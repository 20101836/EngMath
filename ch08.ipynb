{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8. Matrices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "* Matrix Algebra\n",
    "* Systems of Linear Algebraic Equations\n",
    "* Rank of Matrix\n",
    "* Determinants\n",
    "* Properties of Determinants\n",
    "* Inverse of Matrix\n",
    "* Cramer's Rule\n",
    "* The Eigenvalue Problem\n",
    "* Powers of Matrices\n",
    "* Orthogonal Matrices\n",
    "* Approximation of Eigenvalues\n",
    "* Diagonalization\n",
    "* LU-factorization\n",
    "* Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Matrix Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A **matrix** is any rectangular array of numbers or functions\n",
    "\n",
    "  $\n",
    "  \\begin{pmatrix}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n}\\\\ \n",
    "    a_{21} & a_{22} & \\ddots & a_{2n} \\\\ \n",
    "    \\vdots & \\ddots & \\ddots & \\vdots \\\\ \n",
    "    a_{m1} & a_{m2} & \\cdots & a_{mn}\n",
    "  \\end{pmatrix}  \n",
    "  $\n",
    "  \n",
    "  * The numbers or functions in the array are **entries** or **elements**\n",
    "  * An $n \\times n$ matrix  is a **square** matrix of **order $n$**\n",
    "  \n",
    "* **Column** and **row vectors** are $n \\times 1$ and $1 \\times n$ matrices\n",
    "\n",
    "  $\n",
    "  \\begin{pmatrix}\n",
    "    a_1\\\\ \n",
    "    a_2\\\\ \n",
    "    \\vdots\\\\ \n",
    "    a_n\n",
    "  \\end{pmatrix},\\;\n",
    "  \\begin{pmatrix}\n",
    "    a_1 & a_2 & \\cdots & a_n\n",
    "  \\end{pmatrix}  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Equality of Matrices** \n",
    "\n",
    "  $\\mathbf{A} = \\left(a_{ij}\\right)_{m \\times n}$ and $\\mathbf{B} = \\left(b_{ij}\\right)_{m \\times n}$ are **equal** if $a_{ij}=b_{ij}$ for each $i$ and $j$\n",
    "  \n",
    "* **Matrix Addition**\n",
    "\n",
    "  $\\mathbf{A} +\\mathbf{B} = \\left(a_{ij} +b_{ij}\\right)_{m \\times n}$\n",
    "  \n",
    "* **Scalar Multiplication**\n",
    "\n",
    "  $k\\mathbf{A} = \\left(ka_{ij}\\right)_{m \\times n}$\n",
    "  \n",
    "* **Properties of Matrix Addition and Scalar Multiplication**\n",
    "\n",
    "  Suppose $\\mathbf{A}$, $\\mathbf{B}$, and $\\mathbf{C}$ are $m \\times n$ matrices and $k_1$ and $k_2$ are scalars. Then\n",
    "  \n",
    "  $\\mathbf{A} +\\mathbf{B} = \\mathbf{B} +\\mathbf{A}$\n",
    "  \n",
    "  $\\mathbf{A} +\\left(\\mathbf{B} +\\mathbf{C}\\right) = \\left(\\mathbf{A} +\\mathbf{B}\\right) +\\mathbf{C}$\n",
    "\n",
    "  $\\left(k_1 k_2\\right)\\mathbf{A} = k_1 \\left(k_2\\mathbf{A}\\right)$\n",
    "  \n",
    "  $k_1\\left(\\mathbf{A} +\\mathbf{B}\\right)=k_1\\mathbf{A} +k_1\\mathbf{B}$\n",
    "  \n",
    "  $\\left(k_1 +k_2\\right)\\mathbf{A} = k_1 \\mathbf{A} +k_2\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Matrix multiplication** \n",
    "  \n",
    "  $\\displaystyle\\mathbf{A}\\mathbf{B}=\\left(\\sum_{k=1}^p a_{ik} b_{kj}\\right)_{m \\times n}$\n",
    "  \n",
    "  where $\\mathbf{A}$ is an $m \\times p$ matrix, $\\mathbf{B}$ is a $p \\times n$ matrix, and\n",
    "  $\\mathbf{A}\\mathbf{B}$ is the $m \\times n$ matrix\n",
    "  \n",
    "  * In general, $\\mathbf{A}\\mathbf{B}\\neq\\mathbf{B}\\mathbf{A}$\n",
    "  \n",
    "  * **Associative Law:** $\\mathbf{A}\\left(\\mathbf{B}\\mathbf{C}\\right)=\\left(\\mathbf{A}\\mathbf{B}\\right)\\mathbf{C}$ \n",
    "  \n",
    "  * **Distributive Law:** $\\mathbf{A}\\left(\\mathbf{B}+\\mathbf{C}\\right)=\\mathbf{A}\\mathbf{B} +\\mathbf{A}\\mathbf{C}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Transpose of a Matrix**\n",
    "\n",
    "  $\\mathbf{A}^T =\n",
    "  \\begin{pmatrix}\n",
    "    a_{11} & a_{21} & \\cdots & a_{m1}\\\\ \n",
    "    a_{12} & a_{22} & \\ddots & a_{m2} \\\\ \n",
    "    \\vdots & \\ddots & \\ddots & \\vdots \\\\ \n",
    "    a_{1n} & a_{2n} & \\cdots & a_{mn}\n",
    "  \\end{pmatrix}  \n",
    "  $\n",
    "  \n",
    "* **Properties of Transpose**\n",
    "\n",
    "  $\\left(\\mathbf{A}^T\\right)^T=\\mathbf{A}$\n",
    "  \n",
    "  $\\left(\\mathbf{A} +\\mathbf{B}\\right)^T=\\mathbf{A}^T +\\mathbf{B}^T$\n",
    "\n",
    "  $\\left(\\mathbf{A}\\mathbf{B}\\right)^T=\\mathbf{B}^T\\mathbf{A}^T$\n",
    "  \n",
    "  $\\left(k\\mathbf{A}\\right)^T=k\\mathbf{A}^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Special Matrices**\n",
    "\n",
    "  * In a **zero matrix**, all entries zeros\n",
    "  \n",
    "  * In a **triangular matrix**, all entries above or below the main diagonal are zeros(lower triangular or upper triangular)\n",
    "  \n",
    "  * In a **diagonal matrix**, all entries not on the main diagonal are zeros\n",
    "  \n",
    "  * A **scalar matrix** is a diagonal one where all entries on the main diagonal are equal.\n",
    "    If those entries are $1$'s, it is an **identity matrix**, $\\mathbf{I}$ \n",
    "    (or $\\mathbf{I}_n$ when there ia a need to emphasize the order of the matrix)\n",
    "    \n",
    "  * An $n \\times n$ matrix $\\mathbf{A}$ is **symmetric** if $\\mathbf{A}^T=\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.1\n",
    "\n",
    "* 13, 17\n",
    "* 36, 37, 39, 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Systems of Linear Algebraic Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **General Form**\n",
    "\n",
    "  A system of $m$ linear equations in $n$ unknowns has the general form\n",
    "  \n",
    "  $\n",
    "  \\begin{align*}\n",
    "    a_{11} x_1 +a_{12} x_2 + \\cdots +a_{1n} x_n &= b_1\\\\ \n",
    "    a_{21} x_1 +a_{22} x_2 + \\cdots +a_{2n} x_n &= b_2\\\\ \n",
    "     &\\;\\;\\vdots \\\\ \n",
    "    a_{m1} x_1 +a_{m2} x_2 + \\cdots +a_{mn} x_n &= b_m\n",
    "  \\end{align*}  \n",
    "  $\n",
    "  \n",
    "  The **coefficients** of the unknowns can be abbreviated as $a_{ij}$. \n",
    "  The numbers $b_1, b_2, \\cdots, b_m$ are called the **constants** of the system. \n",
    "  If all the constants are zero, the system is said to be **homogeneous**, otherwise it is\n",
    "  **nonhomogeneous**.\n",
    "  \n",
    "  A linear system of equations is said to be **consistent** if it has at least one solution and\n",
    "  **inconsistent** if it has no solutions. If a linear system is consistent, it has either\n",
    "  \n",
    "  * a unique solution (that is, precisely one solution), or\n",
    "  * infinitely many solutions\n",
    "  \n",
    "  ![A linear system of two equations in two variables interpreted as lines in 2-space](figures/ch08_figure01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Augmented Matrix**\n",
    "\n",
    "  $\n",
    "  \\left(\\begin{array}{cccc|c}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n} & b_1\\\\ \n",
    "    a_{21} & a_{22} & \\ddots & a_{2n} & b_2\\\\ \n",
    "    \\vdots & \\ddots & \\ddots & \\vdots & \\vdots\\\\ \n",
    "    a_{m1} & a_{m2} & \\cdots & a_{mn} & b_m\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "* A system can be solved with **elementary operations** (**row reduction** for matrices)\n",
    "  on an augmented matrix\n",
    "  \n",
    "| Elementary Operations | Meaning |\n",
    "|:----------------------|:--------|\n",
    "| $R_{ij}$        | Interchange rows $i$ and $j$                             |\n",
    "| $cR_{i}$        | Multiply the $i$-th row by the nonzero constant $c$      | \n",
    "| $cR_{i}+R_{j}$  | Multiply the $i$-th row by $c$ and add to the $j$-th row |\n",
    "\n",
    "* In the **Gaussian elimination**, we row-reduce the augmented matrix until we arrive \n",
    "  at a row-equivalent augmented matrix in **row-echelon form**\n",
    "  \n",
    "  * The first nonzero entry in a nonzero row is a $1$\n",
    "\n",
    "  * In consecutive nonzero rows, the first entry $1$ in the lower row appears to the right of the $1$ in the higher row\n",
    "  \n",
    "  * Rows consisting of all zeros are at the bottom of the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **Example:** Solve\n",
    "  \n",
    "  $\n",
    "  \\begin{pmatrix}\n",
    "    2 & 6 & \\;\\; 1\\\\ \n",
    "    1 & 2 & -1\\\\ \n",
    "    5 & 7 & -4\n",
    "  \\end{pmatrix}\n",
    "  \\begin{pmatrix}\n",
    "    x_1\\\\ \n",
    "    x_2\\\\ \n",
    "    x_3\n",
    "  \\end{pmatrix}=\n",
    "  \\begin{pmatrix}\n",
    "    \\;\\;7\\\\ \n",
    "    -1\\\\ \n",
    "    \\;\\;9\n",
    "  \\end{pmatrix}  \n",
    "  $\n",
    "  \n",
    "  Using row operations on the augmented matrix, we obtain\n",
    "  \n",
    "  $\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    2 & 6 &  1 & 7\\\\ \n",
    "    1 & 2 & -1 & -1\\\\ \n",
    "    5 & 7 & -4 & 9\n",
    "  \\end{array}\\right) \n",
    "  \\overset{R_{12}}{\\Longrightarrow}  \n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    2 & 6 &  1 & 7\\\\ \n",
    "    5 & 7 & -4 & 9\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\begin{align*}\n",
    "           -2R_1 +&R_2 \\\\ \n",
    "           -5R_1 +&R_3 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 2 &  3 & 9\\\\ \n",
    "    0 & -3 & 1 & 14\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  $\n",
    "  \\overset{\\frac{1}{2}R_2}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & -3 & 1 & 14\n",
    "  \\end{array}\\right)\n",
    "  \\overset{3R_2 +R_3}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & 0 & \\frac{11}{2} & \\frac{55}{2}\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\frac{2}{11}R_3}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & 0 & 1 & 5\n",
    "  \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  The last matrix is in row-echelon form. We can make the last matrix above to be in reduced row-echelon form\n",
    "\n",
    "  $\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & 0 & 1 & 5\n",
    "  \\end{array}\\right)  \n",
    "  \\overset{-2R_2 +R_1}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & -4 & -10\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & 0 & 1 & 5\n",
    "  \\end{array}\\right)   \n",
    "  \\overset{\\begin{align*}\n",
    "           -4R_3 +&R_1 \\\\ \n",
    "          -\\frac{3}{2}R_3 +&R_2 \n",
    "           \\end{align*}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & 0 & 10\\\\   \n",
    "    0 & 1 & 0 & -3 \\\\\n",
    "    0 & 0 & 1 & 5\n",
    "  \\end{array}\\right) \n",
    "  $\n",
    "  \n",
    "  We see that the solution is $x_1=10$, $x_2=-3$, $x_3=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **Example:** Solve\n",
    "  \n",
    "  $\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    1 & 3 & -2\\\\ \n",
    "    4 & 1 & 3\\\\ \n",
    "    2 & -5 & 7\n",
    "  \\end{array}\\right) \n",
    "  \\begin{pmatrix}\n",
    "    x_1\\\\ \n",
    "    x_2\\\\ \n",
    "    x_3\n",
    "  \\end{pmatrix}=\n",
    " \\left(\\begin{array}{r}\n",
    "    -7\\\\ \n",
    "     5\\\\ \n",
    "    19\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Using row operations on the augmented matrix, we obtain\n",
    "  \n",
    "  $\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 3 & -2 & -7\\\\ \n",
    "    4 & 1 &  3 & 5\\\\ \n",
    "    2 & -5 & 7 & 19\n",
    "  \\end{array}\\right) \n",
    "  \\overset{\\begin{align*}\n",
    "           -4R_1 +&R_2 \\\\ \n",
    "           -2R_1 +&R_3 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 3 & -2 & -7\\\\ \n",
    "    0 & -11 & 11 & 33\\\\ \n",
    "    0 & -11 & 11 & 33\n",
    "  \\end{array}\\right) \n",
    "  \\overset{\\begin{align*}\n",
    "           -R_2 +&R_3 \\\\ \n",
    "           -\\frac{1}{11}&R_2 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr:r|r}\n",
    "    1 & 3 & -2 & -7\\\\ \n",
    "    0 & 1 & -1 & -3\\\\ \\hdashline\n",
    "    0 & 0 & 0 & {\\color{Red}0 }\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  In this case, the last matrix implies that the original system of three equations is really equivalent to\n",
    "  two equations. If we let $x_3=t$, $x_1=-t +2$ and $x_2=t -3$, then we see that the system has infinitely many solutions\n",
    "  \n",
    "  $\n",
    "  \\overset{-3R_2 +R_1}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr:r|r}\n",
    "    1 & 0 & 1 & 2\\\\ \n",
    "    0 & 1 & -1 & -3\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)    \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **Example:** Solve\n",
    "  \n",
    "  $\n",
    "  \\left(\\begin{array}{rr}\n",
    "    1 & 1 \\\\ \n",
    "    4 & -1 \\\\ \n",
    "    2 & -3\n",
    "  \\end{array}\\right) \n",
    "  \\begin{pmatrix}\n",
    "    x_1\\\\ \n",
    "    x_2\n",
    "  \\end{pmatrix}=\n",
    " \\left(\\begin{array}{r}\n",
    "    1\\\\ \n",
    "   -6\\\\ \n",
    "    8\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Using row operations on the augmented matrix, we obtain\n",
    "  \n",
    "  $\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 & 1 & 1\\\\ \n",
    "    4 & -1 & -6\\\\ \n",
    "    2 & -3 & 8\n",
    "  \\end{array}\\right) \n",
    "  \\overset{\\begin{align*}\n",
    "           -4R_1 +&R_2 \\\\ \n",
    "           -2R_1 +&R_3 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 & 1 & 1\\\\ \n",
    "    0 & -5 & -10\\\\ \n",
    "    0 & -5 & 6\n",
    "  \\end{array}\\right) \n",
    "  \\overset{\\begin{align*}\n",
    "           -R_2 +&R_3 \\\\ \n",
    "           -\\frac{1}{5}R_2 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 & 1 & 1\\\\ \n",
    "    0 & 1 & 2\\\\ \\hdashline\n",
    "    0 & 0 & {\\color{Red}{16}}\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  The system has no solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A **homogeneous system** of linear equations is **always consistent**. The solution consisting of all zeros is called the **trivial solution**. A homogeneous system either possesses only the trivial solution or possesses the trivial solution along with infinitely many nontrivial solutions\n",
    "\n",
    "* **A homogeneous system possesses nontrivial solutions if the number $m$ of equations is less than the number $n$ of unknowns $(m<n)$**\n",
    "\n",
    "**Example:** Find the positive integers $x_1$, $x_2$, $x_3$, and $x_4$ so that\n",
    "\n",
    "> $x_1 \\mathrm{C_2H_6} +x_2 \\mathrm{O_2} \\rightarrow x_3 \\mathrm{CO_2} +x_4 \\mathrm{H_2O}$\n",
    "\n",
    "> Because the number of atoms of each element must be the same on each side of the last equation, we have:\n",
    "\n",
    "| Atom |      |\n",
    "| ---- | :--- |\n",
    "|$\\mathrm{C}$ |$2x_1=x_3$       |\n",
    "|$\\mathrm{H}$ |$6x_1=2x_4$      |\n",
    "|$\\mathrm{O}$ |$2x_2=2x_3 -x_4$ |\n",
    "\n",
    "> $\n",
    "  \\left(\\begin{array}{rrrr|r}\n",
    "    2 & 0 & -1 &  0 & 0\\\\   \n",
    "    6 & 0 &  0 & -2 & 0\\\\\n",
    "    0 & 2 & -2 & -1 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\begin{align*}\n",
    "             &R_{12} \\\\ \n",
    "             &R_{23} \n",
    "           \\end{align*}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrrr|r}\n",
    "    6 & 0 &  0 & -2 & 0\\\\\n",
    "    0 & 2 & -2 & -1 & 0\\\\\n",
    "    2 & 0 & -1 &  0 & 0  \n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr:r|r} \n",
    "    1 & 0 & 0 & -\\frac{1}{3} & 0\\\\   \n",
    "    0 & 1 & 0 & -\\frac{7}{6} & 0\\\\\n",
    "    0 & 0 & 1 & -\\frac{2}{3} & 0\n",
    "  \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  Then $x_1=\\frac{1}{3}t$, $x_2=\\frac{7}{6}t$, $x_3=\\frac{2}{3}t$, $x_4=t$. If we pick $t=6$, \n",
    "  $x_1=2$, $x_2=7$, $x_3=4$, $x_4=6$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.2\n",
    "\n",
    "* 1, 3, 5, 7, 9, 17, 19\n",
    "* 23, 25, 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Rank of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **rank** of an $m \\times n$ matrix $\\mathbf{A}$, $\\mathrm{rank}(\\mathbf{A})$, is \n",
    "**the maximum number of linearly independent row vectors**. If a matrix $\\mathbf{A}$ is now equivalent to\n",
    "a row-echelon form $\\mathbf{B}$, then\n",
    "\n",
    "* the row space of $\\mathbf{A}$ = the row space of $\\mathbf{B}$\n",
    "* the nonezero rows of $\\mathbf{B}$ form a basis for the row space of $\\mathbf{A}$, and\n",
    "* $\\mathrm{rank}(\\mathbf{A})$ = the number of noezero rows in $\\mathbf{B}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consistency of** $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$\n",
    "\n",
    "A linear system of equations $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ is consistent if and only if $\\mathrm{rank}(\\mathbf{A})=\\mathrm{rank}(\\mathbf{A}|\\mathbf{b})$. \n",
    "\n",
    "Suppose a linear system $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ with $m$ equations and $n$ unknowns is consistent.\n",
    "If $\\mathrm{rank}(\\mathbf{A})=r\\leq n$, then the solution of the system contains $n -r$ parameters. This means that we have the unique solution when $r=n$.\n",
    "\n",
    "  $\n",
    "  \\left(\\begin{array}{cccc|c}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n} & b_1\\\\ \n",
    "    a_{21} & a_{22} & \\ddots & a_{2n} & b_2\\\\ \n",
    "    \\vdots & \\ddots & \\ddots & \\vdots & \\vdots\\\\ \n",
    "    a_{m1} & a_{m2} & \\cdots & a_{mn} & b_m\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{cccc:ccc|c}\n",
    "    1      & a_{12}' & \\cdots & a_{1{\\color{red}r}}'& a_{1r+1}' & \\cdots   & a_{1n}' & b_1' \\\\ \n",
    "    0      & 1       & \\ddots & \\vdots & a_{2r+1}' & \\ddots   & a_{2n}' & b_2' \\\\\n",
    "    \\vdots & \\ddots  & \\ddots & \\vdots & \\vdots    & \\ddots   & \\vdots  & \\vdots \\\\    \n",
    "    0      & \\cdots  & 0      & 1      & a_{{\\color{red}r}r+1}' & \\cdots   & a_{rn}' & b_r' \\\\ \\hdashline     \n",
    "    0      & 0       & 0      & 0      & 0         & 0        & 0       & {\\color{red} 0} \\\\\n",
    "    \\vdots & \\vdots  & \\vdots & \\vdots & \\vdots    & \\vdots   & \\vdots  & {\\color{red} \\vdots} \\\\    \n",
    "    0      & 0       & 0      & 0      & 0         & 0        & 0       & {\\color{red} 0}    \n",
    "  \\end{array}\\right) \n",
    "  $\n",
    "  \n",
    "<img src=\"figures/ch08_figure02.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.3\n",
    "\n",
    "* 1, 3, 5, 9\n",
    "* 11, 13\n",
    "* 15, 16, 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Determinants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Determinant of a $2 \\times 2$ Matrix**\n",
    "\n",
    "  $\\mathrm{det}(\\mathbf{A})=\n",
    "   \\begin{vmatrix}\n",
    "     a_{11} & a_{12}\\\\ \n",
    "     a_{21} & a_{22}\n",
    "   \\end{vmatrix}=a_{11}a_{22}-a_{12}a_{21}\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Determinant of a $3 \\times 3$ Matrix**\n",
    "\n",
    "  $\n",
    "   \\mathrm{det}(\\mathbf{A})=\n",
    "   \\begin{vmatrix}\n",
    "     a_{11} & a_{12} & a_{13}\\\\ \n",
    "     a_{21} & a_{22} & a_{23}\\\\\n",
    "     a_{31} & a_{32} & a_{33}\n",
    "   \\end{vmatrix}=\n",
    "   a_{11}(-1)^{1+1} \n",
    "   \\begin{vmatrix}\n",
    "     a_{22} & a_{23}\\\\ \n",
    "     a_{32} & a_{33}\n",
    "   \\end{vmatrix} +\n",
    "   a_{12}(-1)^{1+2} \n",
    "   \\begin{vmatrix}\n",
    "     a_{21} & a_{23}\\\\ \n",
    "     a_{31} & a_{33}\n",
    "   \\end{vmatrix} +\n",
    "   a_{13}(-1)^{1+3} \n",
    "   \\begin{vmatrix}\n",
    "     a_{21} & a_{22}\\\\ \n",
    "     a_{31} & a_{32}\n",
    "   \\end{vmatrix} \n",
    "  $   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Cofactor and Minor**\n",
    "\n",
    "  The **cofactor of $a_{ij}$** is the determinant\n",
    "  \n",
    "  $C_{ij}=(-1)^{i +j} M_{ij}$\n",
    "  \n",
    "  where $M_{ij}$ is the determinant of the submatrix obtained by deleting the $i$-th row \n",
    "  and the $j$-th column of $\\mathbf{A}$. The determinant $M_{ij}$ is called a **minor determinant** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Cofactor Expansion of a Determinant (Laplace Development)**\n",
    "\n",
    "  Let $\\mathbf{A}=\\left(a_{ij}\\right)_{n \\times n}$ be an $n \\times n$ matrix. For each $1 \\leq i \\leq n$, \n",
    "  **the cofactor expansion of $\\mathrm{det}(\\mathbf{A})$ along the $i$-th row** is\n",
    "  \n",
    "  $\\displaystyle\n",
    "  \\mathrm{det}(\\mathbf{A})=\\sum_{k=1}^na_{ik}C_{ik}$\n",
    "  \n",
    "  For each $1 \\leq j \\leq n$, **the cofactor expansion of $\\mathrm{det}(\\mathbf{A})$ along the $j$-th column** is\n",
    "  \n",
    "  $\\displaystyle\n",
    "  \\mathrm{det}(\\mathbf{A})=\\sum_{k=1}^na_{kj}C_{kj}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.4\n",
    "\n",
    "* 1, 11, 13, 21, 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Properties of Determinants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If $\\mathbf{A}^T$ is the transpose of the $n \\times n$ matrix $\\mathbf{A}$, \n",
    "  then $\\mathrm{det}(\\mathbf{A}^T)=\\mathrm{det}(\\mathbf{A})$\n",
    "  \n",
    "* If any two rows (columns) of an $n \\times n$ matrix $\\mathbf{A}$ are the same, then $\\mathrm{det}(\\mathbf{A})=0$\n",
    "\n",
    "* If all the entries in a row (column) of an $n \\times n$ matrix $\\mathbf{A}$ are zero, then $\\mathrm{det}(\\mathbf{A})=0$\n",
    "\n",
    "* If $\\mathbf{B}$ is the matrix obtained by interchanging any two rows (columns) of an $n \\times n$ matrix $\\mathbf{A}$, then $\\mathrm{det}(\\mathbf{B})=-\\mathrm{det}(\\mathbf{A})$\n",
    "\n",
    "* If $\\mathbf{B}$ is the matrix obtained by multiplying a row (column) by a nonzero real number $k$,\n",
    "  then $\\mathrm{det}(\\mathbf{B})=k\\mathrm{det}(\\mathbf{A})$\n",
    "  \n",
    "* If $\\mathbf{A}$ and $\\mathbf{B}$ are both $n \\times n$ matrices, then \n",
    "  $\\mathrm{det}(\\mathbf{AB})=\\mathrm{det}(\\mathbf{A})\\cdot \\mathrm{det}(\\mathbf{B})$\n",
    "  \n",
    "* Suppose $\\mathbf{B}$ is the matrix obtained from an $n \\times n$ matrix $\\mathbf{A}$ by multiplying the entries\n",
    "  in a row (column) by a nonzero real number $k$ and adding the result to the corresponding entries in another\n",
    "  row (column). Then $\\mathrm{det}(\\mathbf{B})=\\mathrm{det}(\\mathbf{A})$\n",
    "  \n",
    "* If $\\mathbf{A}$ is an $n \\times n$ triangular matrix, then $\\mathrm{det}(\\mathbf{A})=a_{11} a_{22}\\cdots a_{nn}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alien Cofactors**\n",
    "\n",
    "Suppose $\\mathbf{A}$ is an $n \\times n$ matrix. If $a_{i1}, a_{i2}, \\cdots, a_{in}$ are the entries\n",
    "in the $i$-th row and $C_{k1}, C_{k2}, \\cdots, C_{kn}$ are the cofactors of the entries in the $k$-th row, then\n",
    "\n",
    "$\\displaystyle\\sum_{l=1}^n a_{il}C_{kl}=0\\;\\;\\text{for}\\; i \\neq k$\n",
    "\n",
    "If $a_{1j}, a_{2j}, \\cdots, a_{nj}$ are the entries\n",
    "in the $j$-th column and $C_{1k}, C_{2k}, \\cdots, C_{nk}$ are the cofactors of the entries in the $k$-th column, then\n",
    "\n",
    "$\\displaystyle\\sum_{l=1}^n a_{lj}C_{lk}=0\\;\\;\\text{for}\\; j \\neq k$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.5\n",
    "\n",
    "* 1, 3, 5, 11, 12, 16\n",
    "* 18, 20\n",
    "* 24, 25, 26, 28, 38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 Inverse of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If $\\mathbf{A}$ is an $n \\times n$ matrix and there exists an $n \\times n$ matrix $\\mathbf{B}$ such that\n",
    "\n",
    "  $\\mathbf{A}\\mathbf{B}=\\mathbf{B}\\mathbf{A}=\\mathbf{I}$,\n",
    "  \n",
    "  then $\\mathbf{A}$ is said to be **nonsingular** or **invertible** and $\\mathbf{B}$ \n",
    "  is the **inverse** of $\\mathbf{A}$\n",
    "\n",
    "* An $n \\times n$ matrix that has no inverse is called **singular**. If $\\mathbf{A}$ is nonsingular, \n",
    "  its inverse is denoted by $\\mathbf{B}=\\mathbf{A}^{-1}$\n",
    "  \n",
    "* **Properties of the Inverse**\n",
    "\n",
    "  Let $\\mathbf{A}$ and $\\mathbf{B}$ be nonsingular matrices. Then\n",
    "  \n",
    "  * $\\left(\\mathbf{A}^{-1}\\right)^{-1}=\\mathbf{A}$\n",
    "  \n",
    "  * $\\left(\\mathbf{A}\\mathbf{B}\\right)^{-1}=\\mathbf{B}^{-1}\\mathbf{A}^{-1}$\n",
    "  \n",
    "  * $\\left(\\mathbf{A}^T\\right)^{-1}=\\left(\\mathbf{A}^{-1}\\right)^T$\n",
    "  \n",
    "* **Adjoint Matrix**\n",
    "\n",
    "  $\\displaystyle\n",
    "   \\mathrm{adj}(\\mathbf{A})=\n",
    "   \\begin{pmatrix}\n",
    "     C_{11} & C_{12} & \\cdots & C_{1n}\\\\ \n",
    "     C_{21} & C_{22} & \\cdots & C_{2n}\\\\ \n",
    "     \\vdots &        &        & \\vdots\\\\ \n",
    "     C_{n1} & C_{n2} & \\cdots & C_{nn}\n",
    "   \\end{pmatrix}^T   \n",
    "  $\n",
    "  \n",
    "* **Finding the Inverse**\n",
    "  \n",
    "  Let $\\mathbf{A}$ be an $n \\times n$ matrix. If $\\mathrm{det}(\\mathbf{A})\\neq 0$ (**nonsingular**), then\n",
    "  \n",
    "  $\\displaystyle\n",
    "   \\mathbf{A}^{-1}=\\frac{\\mathrm{adj}(\\mathbf{A})}{\\mathrm{det}(\\mathbf{A})}\n",
    "  $\n",
    "\n",
    "  or\n",
    "\n",
    "  ![Finding the Inverse](./figures/ch08_figure03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Using the Inverse to Solve Systems**\n",
    "\n",
    "  The coefficient matrix $\\mathbf{A}$ is $n \\times n$. In particular, if $\\mathbf{A}$ is nonsingular,\n",
    "  the system $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ can be solved by\n",
    "  \n",
    "  $\\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b}$\n",
    "  \n",
    "  A homogeneous system of $n$ linear equations in $n$ unknowns $\\mathbf{A}\\mathbf{x}=\\mathbf{0}$ has\n",
    "  \n",
    "  * only the trivial solution if and only if $\\mathbf{A}$ is nonsingular\n",
    "  \n",
    "  * a nontrivial solution if and only if $\\mathbf{A}$ is singular "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.6\n",
    "\n",
    "* 1, 11, 13\n",
    "* 19, 21, 30, 32\n",
    "* 33 - 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7 Cramer's Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\mathrm{det}(\\mathbf{A}) \\neq 0$, the solution of the system is given by\n",
    "\n",
    "  $\\displaystyle x_k=\\frac{\\mathrm{det}(\\mathbf{A}_k)}{\\mathrm{det}(\\mathbf{A})}$, $k=1, 2, \\cdots, n$\n",
    "  \n",
    "  where\n",
    "\n",
    "  $\\mathbf{A}_k=\n",
    "  \\begin{pmatrix}\n",
    "    a_{11} & \\cdots & a_{1k-1} & b_1    & a_{1k+1} & \\cdots & a_{1n}\\\\ \n",
    "    a_{21} & \\cdots & a_{2k-1} & b_2    & a_{2k+1} & \\ddots & a_{2n} \\\\ \n",
    "    \\vdots &        & \\vdots   & \\vdots & \\vdots   &        & \\vdots\\\\ \n",
    "    a_{n1} & \\cdots & a_{nk-1} & b_n    & a_{nk+1} & \\cdots & a_{nn}\n",
    "  \\end{pmatrix}  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.7\n",
    "\n",
    "* 1, 3, 5, 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8 The Eigenvalue Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let $\\mathbf{A}$ be an $n \\times n$ matrix. A number $\\lambda$ is said to be an **eigenvalue** of \n",
    "  $\\mathbf{A}$ if there exists a nonzero solution vector $\\mathbf{k}$ of the linear system\n",
    "\n",
    "  $\\mathbf{A}\\mathbf{k}=\\lambda\\mathbf{k}$\n",
    "\n",
    "  and the solution vector $\\mathbf{k}$ is said to be an **eigenvector** corresponding to the eigenvalue $\\lambda$\n",
    "  \n",
    "* The problem of solving $\\mathbf{A}\\mathbf{k}=\\lambda\\mathbf{k}$ for nonzero vectors $\\mathbf{k}$ is\n",
    "  called to be the **eigenvalue problem** for $\\mathbf{A}$. \n",
    "  \n",
    "* We must solve the **characteristic equation** \n",
    "  $\\mathrm{det}(\\mathbf{A} -\\lambda\\mathbf{I})=0$ to find an eigenvalue $\\lambda$\n",
    "  \n",
    "* To find an eigenvector $\\mathbf{k}$ corresponding to an eigenvalue $\\lambda$, we solve \n",
    "  $(\\mathbf{A} -\\lambda\\mathbf{I})\\mathbf{k}=\\mathbf{0}$ by applying Gauss elimination \n",
    "  to $(\\mathbf{A} -\\lambda\\mathbf{I}|\\mathbf{0})$\n",
    "  \n",
    "  **Example:** Find the eigenvalues and eigenvectors of\n",
    " \n",
    "  $\\mathbf{A}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    1 & 2 &  1\\\\ \n",
    "    6 &-1 &  0\\\\ \n",
    "   -1 &-2 & -1\n",
    "  \\end{array}\\right)   \n",
    "  $\n",
    "  \n",
    "  To find the eigenvalues, we solve\n",
    "  \n",
    "  $\n",
    "  \\mathrm{det} (\\mathbf{A} -\\lambda\\mathbf{I}) =\n",
    "  \\begin{vmatrix}\n",
    "    1 -\\lambda & \\;\\;\\,2 & \\;\\;\\,1\\\\ \n",
    "    6 & -1 -\\lambda & \\;\\;\\,0\\\\ \n",
    "    -1\\;\\;\\, & -2 & -1 -\\lambda\n",
    "  \\end{vmatrix}=0  \n",
    "  $\n",
    "  \n",
    "  It follows that the characteristic equation is \n",
    "  \n",
    "  $-\\lambda^3 -\\lambda^2 +12\\lambda=-\\lambda(\\lambda+4)(\\lambda-3)=0$\n",
    "  \n",
    "  Hence the eigenvalues are $\\lambda_1=0$, $\\lambda_2=-4$, $\\lambda_3=3$\n",
    "  \n",
    "  For $\\lambda_1=0$, we have\n",
    "  \n",
    "  $\n",
    "  (\\mathbf{A} -0\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 &  1 & 0\\\\ \n",
    "    6 &-1 &  0 & 0\\\\ \n",
    "   -1 &-2 & -1 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & \\frac{1}{13} & 0\\\\ \n",
    "    0 & 1 & \\frac{6}{13} & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=-\\frac{1}{13}k_3$, $k_2=-\\frac{6}{13}k_3$. Choosing $k_3=13$ gives the eigenvector\n",
    "  \n",
    "  $\\mathbf{k}_1=\n",
    "  \\left(\\begin{array}{r}\n",
    "    1\\\\ \n",
    "    6\\\\ \n",
    "  -13\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  For $\\lambda_2=-4$, we have\n",
    "  \n",
    "  $\n",
    "  (\\mathbf{A} +4\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    5 & 2 &  1 & 0\\\\ \n",
    "    6 & 3 &  0 & 0\\\\ \n",
    "   -1 &-2 &  3 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & 1 & 0\\\\ \n",
    "    0 & 1 &-2 & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=-k_3$, $k_2=2k_3$. Choosing $k_3=1$ gives the eigenvector\n",
    "  \n",
    "  $\\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "    -1\\\\ \n",
    "     2\\\\ \n",
    "     1\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  For $\\lambda_3=3$, we have\n",
    "  \n",
    "  $\n",
    "  (\\mathbf{A} -3\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "   -2 & 2 &  1 & 0\\\\ \n",
    "    6 &-4 &  0 & 0\\\\ \n",
    "   -1 &-2 & -4 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & 1 & 0\\\\ \n",
    "    0 & 1 & \\frac{3}{2} & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=-k_3$, $k_2=-\\frac{3}{2}k_3$. Choosing $k_3=-2$ gives the eigenvector\n",
    "  \n",
    "  $\\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "    2\\\\ \n",
    "    3\\\\ \n",
    "   -2\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  **Example:** Find the eigenvalues and eigenvectors of \n",
    "  $\\mathbf{A}=\n",
    "   \\left(\\begin{array}{rr}\n",
    "     3 & 4 \\\\ \n",
    "    -1 & 7 \n",
    "   \\end{array}\\right)$\n",
    "   \n",
    "   From the characteristic equation\n",
    "   \n",
    "   $\n",
    "   \\mathrm{det}(\\mathbf{A} -\\lambda\\mathbf{I})=\n",
    "   \\left|\\begin{array}{cc}\n",
    "     3-\\lambda & 4 \\\\ \n",
    "    -1 & 7 -\\lambda \n",
    "   \\end{array}\\right|\n",
    "   =(\\lambda -5)^2=0\n",
    "   $,\n",
    "   \n",
    "   we see $\\lambda_1=\\lambda_2=5$ is an eigenvalue of algebraic multiplicity 2. To find\n",
    "   the eigenvector(s) corresponding to $\\lambda_1=5$, we resort to \n",
    "   the system $(\\mathbf{A} -5\\mathbf{I}|\\mathbf{0})$\n",
    "   \n",
    "  $\n",
    "  (\\mathbf{A} -5\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "   -2 & 4 & 0\\\\ \n",
    "   -1 & 2 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 &-2 & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=2k_2$. If we choose $k_2=1$, we find the single eigenvector \n",
    "  \n",
    "  $\\mathbf{k}_1=\\begin{pmatrix}\n",
    "     2 \\\\ 1\n",
    "   \\end{pmatrix}$ \n",
    "   \n",
    "  We define the geometric multiplicity of an eigenvalue\n",
    "  to be the number of linearly independent eigenvectors for the eigenvalue.\n",
    "  When the geometric multiplicity of an eigenvalue is less than the algebraic \n",
    "  multiplicity, we say the matrix is *defective*. In the case of defective matrices,\n",
    "we must search for additional system \n",
    "\n",
    "  $\n",
    "  (\\mathbf{A} -5\\mathbf{I}|\\mathbf{k}_1) =\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "   -2 & 4 & 2\\\\ \n",
    "   -1 & 2 & 1\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 &-2 & -1\\\\ \\hdashline\n",
    "    0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1-2k_2=-1$. If we choose $k_2=0$, we find the generalized eigenvector\n",
    "  \n",
    "  $\\mathbf{k}_2=\\begin{pmatrix}\n",
    "     -1 \\\\ \\;\\;0\n",
    "   \\end{pmatrix}$\n",
    "   \n",
    "  **Example:** Find the eigenvalues and eigenvectors of\n",
    " \n",
    "  $\\mathbf{A}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    9 & 1 & 1\\\\ \n",
    "    1 & 9 & 1\\\\ \n",
    "    1 & 1 & 9\n",
    "  \\end{array}\\right)   \n",
    "  $\n",
    "  \n",
    "  The characteristic equation\n",
    "  \n",
    "  $\n",
    "  \\mathrm{det} (\\mathbf{A} -\\lambda\\mathbf{I}) =\n",
    "  \\begin{vmatrix}\n",
    "    9 -\\lambda & 1 & 1\\\\ \n",
    "    1 & 9 -\\lambda & 1\\\\ \n",
    "    1 & 1 & 9 -\\lambda\n",
    "  \\end{vmatrix}=-(\\lambda-11)(\\lambda-8)^2=0  \n",
    "  $\n",
    "  \n",
    "  shows that $\\lambda_1=11$ and that $\\lambda_2=\\lambda_3=8$ is an eigenvalue of multiplicity 2\n",
    "  \n",
    "  For $\\lambda_1=11$, we have\n",
    "  \n",
    "  $\n",
    "  (\\mathbf{A} -11\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "   -2 & 1 &  1 & 0\\\\ \n",
    "    1 &-2 &  1 & 0\\\\ \n",
    "    1 & 1 & -2 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & -1 & 0\\\\ \n",
    "    0 & 1 & -1 & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=k_3$, $k_2=k_3$. Choosing $k_3=1$ gives the eigenvector\n",
    "  \n",
    "  $\\mathbf{k}_1=\n",
    "  \\left(\\begin{array}{r}\n",
    "    1\\\\ \n",
    "    1\\\\ \n",
    "    1\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  For $\\lambda_2=8$, we have\n",
    "  \n",
    "  $\n",
    "  (\\mathbf{A} -8\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 1 &  1 & 0\\\\ \n",
    "    1 & 1 &  1 & 0\\\\ \n",
    "    1 & 1 &  1 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 1 & 1 & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\\\\ \n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Here $k_1 +k_2 +k_3=0$, we are free to select two of the variables arbitrarily.\n",
    "  Choosing, on the one hand, $k_2=1$, $k_3=0$, and on the other, $k_2=0$, $k_3=1$, we obtain\n",
    "  two linearly independent eigenvectors\n",
    "  \n",
    "  $\\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -1\\\\ \n",
    "    1\\\\ \n",
    "    0\n",
    "  \\end{array}\\right) \\text{ and } \n",
    "  \\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -1\\\\ \n",
    "    0\\\\ \n",
    "    1\n",
    "  \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  corresponding to a single eigenvalue. If instead we choose $k_2=1$, $k_3=1$ and then $k_2=1$, $k_3=-1$, we obtain,\n",
    "  respectively, two entirely different but orthogonal eigenvectors\n",
    "  \n",
    "  $\\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -2\\\\ \n",
    "    1\\\\ \n",
    "    1\n",
    "  \\end{array}\\right) \\text{ and } \n",
    "  \\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "    0\\\\ \n",
    "    1\\\\ \n",
    "   -1\n",
    "  \\end{array}\\right)\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let $\\mathbf{A}$ be a square matrix with real entries. If $\\lambda=\\alpha +i\\beta$, $\\beta \\neq 0$,\n",
    "  is a complex eigenvalue of $\\mathbf{A}$,\n",
    "  \n",
    "  $\\mathbf{A}\\mathbf{\\bar{k}}=\\bar{\\lambda}\\mathbf{\\bar{k}}$\n",
    "  \n",
    "* $\\lambda=0$ is an eigenvalue of $\\mathbf{A}$ if and only if $\\mathbf{A}$ is singular\n",
    "\n",
    "* If $\\lambda$ is an eigenvalue of nonsingular $\\mathbf{A}$ with eigenvector $\\mathbf{k}$,\n",
    "  $1/\\lambda$ is an eigenvalue of $\\mathbf{A}^{-1}$ with the same eigenvector $\\mathbf{k}$\n",
    "  \n",
    "* The eigenvalues of an upper triangular, lower triangular, and diagonal matrix are the main diagonal entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.8\n",
    "\n",
    "* 1, 3, 7, 13, 19\n",
    "* 23, 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.9 Powers of Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Cayley-Hamilton Theorem**\n",
    "\n",
    "  If $(-1)^n \\lambda^n +c_{n-1}\\lambda^{n-1} + \\cdots +c_1 \\lambda +c_0 = 0$ is the characteristic equation\n",
    "  of $n \\times n$ matrix $\\mathbf{A}$, then\n",
    "  \n",
    "  $(-1)^n \\mathbf{A}^n +c_{n-1}\\mathbf{A}^{n-1} + \\cdots +c_1 \\mathbf{A} +c_0 \\mathbf{I} = \\mathbf{0}$\n",
    "  \n",
    "  And we can write\n",
    "  \n",
    "    $\\mathbf{A}^m = c_0 \\mathbf{I} +c_1 \\mathbf{A} +\\cdots +c_{n-1}\\mathbf{A}^{n-1}$\n",
    "    \n",
    "    and the equation for the eigenvalues\n",
    "    \n",
    "    $\\lambda^m = c_0 +c_1 \\lambda +\\cdots +c_{n-1}\\lambda^{n-1}$\n",
    "    \n",
    "    hold for the same constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.9\n",
    "\n",
    "* 1, 3, 5, 7\n",
    "* 11, 12, 13, 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.10 Orthogonal Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let $\\mathbf{A}$ be a *symmetric* matrix ($\\mathbf{A}=\\mathbf{A}^T$) with *real* entries. Then the eigenvalues of $\\mathbf{A}$ are *real*\n",
    "\n",
    "* Let $\\mathbf{A}$ be a *symmetric* matrix. Then eigenvectors corresponding to distinct(different) eigenvalues are *orthogonal*\n",
    "\n",
    "* An $n \\times n$ matrix $\\mathbf{A}$ is *orthogonal* ($\\mathbf{A}^{-1}=\\mathbf{A}^T$) if and only if its columns $\\mathbf{x}_1$, $\\mathbf{x}_2$, \n",
    "  $\\cdots$, $\\mathbf{x}_n$ form an orthonormal set\n",
    "  \n",
    "  $\\mathbf{x}_i \\cdot \\mathbf{x}_j=0$, $i \\neq j$ and $\\mathbf{x}_i \\cdot \\mathbf{x}_i=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It may not be possible to find $n$ linearly independent eigenvectors for an $n \\times n$ matrix $\\mathbf{A}$\n",
    "  when some of eigenvalues are repeated (defective matrix). \n",
    "  \n",
    "* But a symmetric matrix is an exception. It can be proved that a set of \n",
    "  $n$ linearly independent eigenvectors can always be found for an $n \\times n$ symmetric matrix $\\mathbf{A}$ even\n",
    "  there is some repetition of the eigenvalues\n",
    "  \n",
    "* However, this does not mean that all eigenvectors are mutually orthogonal for an $n \\times n$ symmetric matrix $\\mathbf{A}$.\n",
    "  The set of eigenvectors corresponding to distinct eigenvalues are orthogonal; but different eigenvectors corresponding to \n",
    "  a repeated eigenvalue may not be orthogonal\n",
    "  \n",
    "* But it is always possible to *find* or *construct* a set of $n$ mutually orthogonal eigenvectors by using Gram-Schmidt orthogonalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Construct an orthogonal matrix from the eigenvectors of\n",
    "\n",
    "> $\n",
    "  \\mathbf{A}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    7 & 4 & -4\\\\ \n",
    "    4 &-8 & -1\\\\ \n",
    "   -4 &-1 & -8\n",
    "  \\end{array}\\right)   \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.10\n",
    "\n",
    "* 1, 3, 5, 7\n",
    "* 11, 13, 21\n",
    "* 25 - 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.11 Approximation of Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\lambda_1$, $\\lambda_2$, $\\cdots$, $\\lambda_k$, $\\cdots$, $\\lambda_n$ denote the eigenvalues of an $n \\times n$ matrix $\\mathbf{A}$.\n",
    "The eigenvalue $\\lambda_k$ is said to be the **dominant eigenvalue** of $\\mathbf{A}$ if\n",
    "\n",
    "> $|\\lambda_k| > |\\lambda_i|$, $i=1,2,\\cdots,n$, but $i \\neq k$\n",
    "\n",
    "An eigenvector corresponding to $\\lambda_k$ is called the **dominant eigenvector** of $\\mathbf{A}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Power Method**\n",
    "\n",
    "  Let us assume that the eigenvalues of $\\mathbf{A}$ are such that\n",
    "  \n",
    "  > $|\\lambda_1| > |\\lambda_2| \\geq |\\lambda_3| \\geq \\cdots \\geq |\\lambda_n|$\n",
    "  \n",
    "  and that the corresponding $n$ eigenvectors $\\mathbf{k}_1$, $\\mathbf{k}_2$, $\\cdots$, $\\mathbf{k}_n$\n",
    "  are linearly independent. Because of this last assumption, $n$ eigenvectors\n",
    "  can serve as a basis for $\\mathbb{R}^n$. For any nonzero $n \\times 1$ vector $\\mathbf{x}_0$, \n",
    "  \n",
    "  > $\\mathbf{x}_0 =c_1 \\mathbf{k}_1 +c_2 \\mathbf{k}_2 +c_3 \\mathbf{k}_3 +\\cdots +c_n \\mathbf{k}_n$\n",
    "  \n",
    "  We shall also assume $\\mathbf{x}_0$ is chosen so that $c_1 \\neq 0$. We do the following procedure\n",
    "  \n",
    "  >$\n",
    "  \\begin{align*}\n",
    "     \\mathbf{A}\\mathbf{x}_0 &= c_1 \\mathbf{A}\\mathbf{k}_1 +c_2 \\mathbf{A}\\mathbf{k}_2 \n",
    "         +c_3 \\mathbf{A}\\mathbf{k}_3 +\\cdots +c_n \\mathbf{A}\\mathbf{k}_n\\\\ \n",
    "     &\\;\\big\\Downarrow \\;\\;\\mathbf{x}_i=\\mathbf{A}\\mathbf{x}_{i -1}, \\;\\mathbf{A}\\mathbf{k}_j=\\lambda_j \\mathbf{k}_j\\\\ \n",
    "     \\mathbf{x}_1 &= c_1 \\lambda_1\\mathbf{k}_1 +c_2 \\lambda_2\\mathbf{k}_2 \n",
    "         +c_3 \\lambda_3\\mathbf{k}_3 +\\cdots +c_n \\lambda_n\\mathbf{k}_n\\\\ \n",
    "     &\\Downarrow \\\\\n",
    "     \\mathbf{A}\\mathbf{x}_1 &= c_1 \\lambda_1\\mathbf{A}\\mathbf{k}_1 +c_2 \\lambda_2\\mathbf{A}\\mathbf{k}_2 \n",
    "         +c_3 \\lambda_3\\mathbf{A}\\mathbf{k}_3 +\\cdots +c_n \\lambda_n\\mathbf{A}\\mathbf{k}_n\\\\ \n",
    "     &\\Downarrow \\\\\n",
    "     \\mathbf{x}_2 &= c_1 \\lambda_1^2\\mathbf{k}_1 +c_2 \\lambda_2^2\\mathbf{k}_2 \n",
    "         +c_3 \\lambda_3^2\\mathbf{k}_3 +\\cdots +c_n \\lambda_n^2\\mathbf{k}_n\\\\\n",
    "     &\\Downarrow \\\\\n",
    "     \\mathbf{x}_m &= c_1 \\lambda_1^m\\mathbf{k}_1 +c_2 \\lambda_2^m\\mathbf{k}_2 \n",
    "         +c_3 \\lambda_3^m\\mathbf{k}_3 +\\cdots +c_n \\lambda_n^m\\mathbf{k}_n\\\\ \n",
    "     &= \\lambda_1^m \\left[c_1 \\mathbf{k}_1 +c_2 \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^m\\mathbf{k}_2 \n",
    "         +c_3 \\left(\\frac{\\lambda_3}{\\lambda_1}\\right)^m\\mathbf{k}_3 +\\cdots +c_n \\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^m\\mathbf{k}_n \\right]\\\\        &\\;\\big\\Downarrow \\;\\;m \\rightarrow \\infty\\\\\n",
    "     \\mathbf{x}_m &\\simeq \\lambda_1^m c_1 \\mathbf{k}_1   \n",
    "  \\end{align*}  \n",
    "  $\n",
    "  \n",
    "  Since a nonzero constant multiple of an eigenvalue is an eigenvector, for large values of $m$ and under all the assumptions\n",
    "  that were made, the $n \\times 1$ vector $\\mathbf{x}_m$ is an approximation to a dominant eigenvector associated with\n",
    "  the dominant eigenvalue $\\lambda_1$\n",
    "  \n",
    "  If $\\mathbf{x}_m$ is an approximation to a dominant eigenvector, then the dominant eigenvalue $\\lambda_1$ can be approximated by\n",
    "  the **Rayleigh quotient**\n",
    "  \n",
    "  >$\\displaystyle\n",
    "   \\lambda_1=\\frac{\\mathbf{A}\\mathbf{x}_m \\cdot \\mathbf{x}_m}{\\mathbf{x}_m \\cdot \\mathbf{x}_m}\n",
    "  $\n",
    "  \n",
    "  Iteration often results in vectors whose entries become very large. Large numbers can cause a problem in computation. One way around\n",
    "  this difficulty is to use a **scaled-down** normalized vector\n",
    "  \n",
    "  >$\\displaystyle\n",
    "  \\mathbf{x}_m \\leftarrow \n",
    "    \\frac{\\mathbf{x}_m}{\\left \\| \\mathbf{x}_m \\right \\|}\n",
    "  $\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "array([[ 4,  2],\n",
      "       [ 3, -1]])\n",
      "\n",
      "Dominant Eigenvector :  [0.89437542 0.44731713]\n",
      "Dominant Eigenvalue  :  4.999884153206596\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "def power_method(A, n_iteration):\n",
    "    # Ideally choose a random vector\n",
    "    # To decrease the chance that our vector\n",
    "    # is orthogonal to the eigenvector\n",
    "    k = np.random.rand(A.shape[1])\n",
    "\n",
    "    for _ in range(n_iteration):\n",
    "        # calculate the matrix-by-vector product Ak\n",
    "        k_1 = np.dot(A, k)\n",
    "\n",
    "        # calculate the norm\n",
    "        k_1_norm = np.linalg.norm(k_1)\n",
    "\n",
    "        # re normalize the vector\n",
    "        k = k_1 /k_1_norm\n",
    "\n",
    "    return k\n",
    "\n",
    "def Rayleigh_quotient(A, k):\n",
    "    # calculate Rayleigh quotient\n",
    "    lambda_ = np.dot(np.dot(A, k), k) /np.dot(k, k)\n",
    "    \n",
    "    return lambda_\n",
    "\n",
    "A = np.array([[4, 2], [3, -1]])\n",
    "k_1 = power_method(A, 10)\n",
    "lambda_1 = Rayleigh_quotient(A, k_1)\n",
    "\n",
    "print('A =')\n",
    "pprint.pprint(A)\n",
    "print('\\nDominant Eigenvector : ', k_1)\n",
    "print('Dominant Eigenvalue  : ', lambda_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Method of Deflation**\n",
    "\n",
    "  After we have found the dominant eigenvalue $\\lambda_1$ of a matrix $\\mathbf{A}$, it may still be necessary to find\n",
    "  nondominant eigenvalues. We will limit the discussion to the case where $\\mathbf{A}$ is a *symmetric* matrix.\n",
    "  \n",
    "  Suppose $\\lambda_!$ and $\\mathbf{k}_1$ are, respectively, the dominant eigenvalue and a corresponding *normalized* eigenvector of\n",
    "  a symmetric matrix $\\mathbf{A}$. Forthermore, suppose the eigenvalues of $\\mathbf{A}$ are such that\n",
    "  \n",
    "  > $|\\lambda_1| > |\\lambda_2| > |\\lambda_3| \\geq \\cdots \\geq |\\lambda_n|$\n",
    "  \n",
    "  In this case, the matrix\n",
    "  \n",
    "  > $\\mathbf{A}_1 =\\mathbf{A} -\\lambda_1\\mathbf{k}_1\\mathbf{k}_1^T$\n",
    "  \n",
    "  has eigenvalues $0$, $|\\lambda_2|$, $|\\lambda_3|$, $\\cdots$, $|\\lambda_n|$ and that eigenvectors of $\\mathbf{A}_1$ are also eigenvectors \n",
    "  of $\\mathbf{A}$. Note that $\\lambda_2$ is now the dominant eigenvalue of $\\mathbf{A}_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "array([[ 1,  2, -1],\n",
      "       [ 2,  1,  1],\n",
      "       [-1,  1,  0]])\n",
      "\n",
      "k_1 =  [ 7.06877739e-01  7.07335712e-01 -2.28952766e-04]\n",
      "k_2 =  [-0.57694013  0.57778144 -0.57732894]\n",
      "k_3 =  [-0.40827835  0.40827828  0.81646656]\n",
      "\n",
      "lambda_1 =  2.99999921355512\n",
      "lambda_2 =  -2.000001177637534\n",
      "lambda_3 =  1.0000000040566355\n"
     ]
    }
   ],
   "source": [
    "def deflation_method(A, n_iteration):\n",
    "    \n",
    "    n = A.shape[1]\n",
    "\n",
    "    K = np.zeros((n, n))\n",
    "    Lambda = np.zeros(n)\n",
    "    \n",
    "    k0 = np.zeros(n)\n",
    "    L0 = 0\n",
    "    for i in range(n):\n",
    "        A = A -L0 *np.outer(k0, k0)\n",
    "        k0 = power_method(A, n_iteration)\n",
    "        L0 = Rayleigh_quotient(A, k0)\n",
    "        K[i, :] = k0\n",
    "        Lambda[i] = L0\n",
    "        \n",
    "    return K, Lambda      \n",
    "\n",
    "# symmetric matrix\n",
    "A = np.array([[1, 2, -1], [2, 1, 1], [-1, 1, 0]])\n",
    "\n",
    "K, Lambda = deflation_method(A, 15)  \n",
    "\n",
    "print('A =')\n",
    "pprint.pprint(A)\n",
    "    \n",
    "print('\\nk_1 = ', K[0, :])\n",
    "print('k_2 = ', K[1, :])\n",
    "print('k_3 = ', K[2, :])\n",
    "\n",
    "print('\\nlambda_1 = ', Lambda[0])\n",
    "print('lambda_2 = ', Lambda[1])\n",
    "print('lambda_3 = ', Lambda[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Inverse Power Method**\n",
    "\n",
    "  If we want to find the smallest eigenvalue instead of the largest one, then we perform power\n",
    "  iteration for $\\mathbf{A}^{−1}$ (since the eigenvalues of $\\mathbf{A}^{-1}$ are the reciprocals of the eigenvalues of\n",
    "  $\\mathbf{A}$). Of course, we do not want to compute $\\mathbf{A}^{-1}$\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "array([[ 4,  2],\n",
      "       [ 3, -1]])\n",
      "\n",
      "Eigenvector =  [ 0.3168287  -0.94848278]\n",
      "Eigenvalue of Least Magnitude =  -2.000630695446505\n"
     ]
    }
   ],
   "source": [
    "def inverse_power_method(A, n_iteration):\n",
    "    # Ideally choose a random vector\n",
    "    # To decrease the chance that our vector\n",
    "    # is orthogonal to the eigenvector\n",
    "    k = np.random.rand(A.shape[1])\n",
    "\n",
    "    for _ in range(n_iteration):\n",
    "        # calculate the matrix-by-vector product Ak\n",
    "        w = np.linalg.solve(A, k)\n",
    "\n",
    "        # calculate the norm\n",
    "        w_norm = np.linalg.norm(w)\n",
    "\n",
    "        # re normalize the vector\n",
    "        k = w /w_norm\n",
    "\n",
    "    return k\n",
    "\n",
    "A = np.array([[4, 2], [3, -1]])\n",
    "k_2 = inverse_power_method(A, 10)\n",
    "lambda_2 = Rayleigh_quotient(A, k_2)\n",
    "\n",
    "print('A =')\n",
    "pprint.pprint(A)\n",
    "print('\\nEigenvector = ', k_2)\n",
    "print('Eigenvalue of Least Magnitude = ', lambda_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.11\n",
    "\n",
    "* 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.12 Diagonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an $n \\times n$ matrix $\\mathbf{A}$, can we find an $n \\times n$ nonsingular matrix $\\mathbf{P}$ such that \n",
    "$\\mathbf{P}^{-1}\\mathbf{A}\\mathbf{P}=\\mathbf{D}$ is a diagonal matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* An $n \\times n$ matrix $\\mathbf{A}$ is diagonalizable if and only if $\\mathbf{A}$ has $n$ linearly independent eigenvectors\n",
    "\n",
    "  Let $\\mathbf{k}_1$, $\\mathbf{k}_2$, $\\cdots$, $\\mathbf{k}_n$ be linearly independent eigenvectors corresponding to \n",
    "  eigenvalues $\\lambda_1$, $\\lambda_2$, $\\cdots$, $\\lambda_n$. Next form the matrix $\\mathbf{P}$ with column vectors\n",
    "  $\\mathbf{k}_1$, $\\mathbf{k}_2$, $\\cdots$, $\\mathbf{k}_n$\n",
    "  \n",
    "  >$\n",
    "  \\mathbf{P}= \\begin{pmatrix}\n",
    "    \\mathbf{k}_1 & \\mathbf{k}_2 & \\cdots & \\mathbf{k}_n\n",
    "  \\end{pmatrix}\n",
    "  $\n",
    "  \n",
    "  We can wrtie the product $\\mathbf{A}\\mathbf{P}$ as\n",
    "  \n",
    "  >$\n",
    "  \\begin{align*}\n",
    "   \\mathbf{A}\\mathbf{P}\n",
    "      &= \n",
    "      \\begin{pmatrix}\n",
    "        \\mathbf{A}\\mathbf{k}_1 & \\mathbf{A}\\mathbf{k}_2 & \\cdots & \\mathbf{A}\\mathbf{k}_n \n",
    "      \\end{pmatrix} =\n",
    "      \\begin{pmatrix}\n",
    "        \\lambda_1\\mathbf{k}_1 & \\lambda_2\\mathbf{k}_2 & \\cdots & \\lambda_n\\mathbf{k}_n \n",
    "      \\end{pmatrix} \\\\\n",
    "      &=\\begin{pmatrix}\n",
    "           \\mathbf{k}_1 & \\mathbf{k}_2 & \\cdots & \\mathbf{k}_n\n",
    "        \\end{pmatrix}\n",
    "        \\begin{pmatrix}\n",
    "           \\lambda_1 &  &  & \\\\ \n",
    "                     & \\lambda_2 &  & \\\\ \n",
    "                     &  & \\ddots & \\\\ \n",
    "                     &  &  & \\lambda_n\n",
    "        \\end{pmatrix}=\\mathbf{P}\\mathbf{D}\n",
    "  \\end{align*}  \n",
    "  $\n",
    "  \n",
    "  Multiplying the last equation on the left by $\\mathbf{P}^{-1}$ then gives $\\mathbf{P}^{-1}\\mathbf{A}\\mathbf{P}=\\mathbf{D}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/ch08_figure04.png\" width=\"400\">\n",
    "\n",
    "* If an $n \\times n$ matrix $\\mathbf{A}$ has $n$ distinct eigenvalues, it is diagonalizable\n",
    "* An $n \\times n$ matrix $\\mathbf{A}$ can be *orthogonally* diagonalized if and only if $\\mathbf{A}$ is symmetric\n",
    "\n",
    "  **Example:** Diagonalize\n",
    "\n",
    "  $\\mathbf{A}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    9 & 1 & 1\\\\ \n",
    "    1 & 9 & 1\\\\ \n",
    "    1 & 1 & 9\n",
    "  \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  The eigenvalues and corresponding orthogonal eigenvectors are\n",
    "  \n",
    "  $\\lambda_1=11$, $\\lambda_2=\\lambda_3=8$\n",
    "  \n",
    "  $\\mathbf{k}_1=\n",
    "  \\left(\\begin{array}{r}\n",
    "    1\\\\ \n",
    "    1\\\\ \n",
    "    1\n",
    "  \\end{array}\\right),  \n",
    "  \\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -2\\\\ \n",
    "    1\\\\ \n",
    "    1\n",
    "  \\end{array}\\right) \\text{ and } \n",
    "  \\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "    0\\\\ \n",
    "    1\\\\ \n",
    "   -1\n",
    "  \\end{array}\\right)\n",
    "  $  \n",
    "  \n",
    "  Multiplying these vectors, in turn, by the reciprocals of the norms $\\left \\| \\mathbf{k}_1 \\right \\|=\\sqrt{3}$,\n",
    "  $\\left \\| \\mathbf{k}_2 \\right \\|=\\sqrt{6}$ and $\\left \\| \\mathbf{k}_3 \\right \\|=\\sqrt{2}$,\n",
    "  we obtain an orthonormal set\n",
    "  \n",
    "  $\n",
    "  \\mathbf{k}_1=\n",
    "  \\left(\\begin{array}{r}\n",
    "    \\frac{1}{\\sqrt{3}}\\\\ \n",
    "    \\frac{1}{\\sqrt{3}}\\\\ \n",
    "    \\frac{1}{\\sqrt{3}}\n",
    "  \\end{array}\\right),  \n",
    "  \\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "    -\\frac{2}{\\sqrt{6}}\\\\ \n",
    "     \\frac{1}{\\sqrt{6}}\\\\ \n",
    "     \\frac{1}{\\sqrt{6}}\n",
    "  \\end{array}\\right) \\text{ and } \n",
    "  \\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "    0\\;\\\\ \n",
    "    \\frac{1}{\\sqrt{2}}\\\\ \n",
    "   -\\frac{1}{\\sqrt{2}}\n",
    "  \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  We then use these vectors as columns to construct an orthogonal matrix that diagonalizes $\\mathbf{A}$\n",
    "  \n",
    "  $\\mathbf{P}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    \\frac{1}{\\sqrt{3}} & -\\frac{2}{\\sqrt{6}} &  0\\;\\\\ \n",
    "    \\frac{1}{\\sqrt{3}} &  \\frac{1}{\\sqrt{6}} &  \\frac{1}{\\sqrt{2}}\\\\ \n",
    "    \\frac{1}{\\sqrt{3}} &  \\frac{1}{\\sqrt{6}} & -\\frac{1}{\\sqrt{2}}\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  This transforms $\\mathbf{A}$ to $\\mathbf{D}$\n",
    "  \n",
    "  $\\mathbf{P}^{-1}\\mathbf{A}\\mathbf{P}=\\mathbf{P}^{T}\\mathbf{A}\\mathbf{P}=\n",
    "   \\begin{pmatrix}\n",
    "    11 & 0 & 0\\\\ \n",
    "     0 & 8 & 0\\\\ \n",
    "     0 & 0 & 8\n",
    "   \\end{pmatrix}=\\mathbf{D}$\n",
    "   \n",
    "   The entries in $\\mathbf{D}$ are the eigenvalues of $\\mathbf{A}$ and the order in which these numbers appear on the diagonal\n",
    "   corresponds to the order in which the eigenvectors are used as columns in the matrix $\\mathbf{P}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Quadratic Forms**\n",
    "\n",
    "  **Example:** Identify the conic section whose equation $2x^2 +4xy -y^2 =1$\n",
    "  \n",
    "  We can write the given equation as\n",
    "  \n",
    "  $\n",
    "  \\begin{pmatrix}\n",
    "    x & y\n",
    "  \\end{pmatrix}\n",
    "  \\left(\\begin{array}{rr}\n",
    "    2 & 2\\\\ \n",
    "    2 &-1 \n",
    "  \\end{array}\\right)\n",
    "  \\begin{pmatrix}\n",
    "    x \\\\ \n",
    "    y\n",
    "  \\end{pmatrix}\n",
    "  =1 \\;\\text{ or }\\; \\mathbf{x}^T\\mathbf{A}\\mathbf{x}=1\n",
    "  $\n",
    "  \n",
    "  The eigenvalues and corresponding eigenvectors of $\\mathbf{A}$ are found to be\n",
    "  \n",
    "  $\\lambda_1=-2$, $\\lambda_2=3$, $\\mathbf{k}_1=\\left(\\begin{array}{r} 1\\\\ -2 \\end{array}\\right)$,\n",
    "  $\\mathbf{k}_2=\\left(\\begin{array}{r} 2\\\\ 1 \\end{array}\\right)$\n",
    "  \n",
    "  Observe that $\\mathbf{k}_1$ and $\\mathbf{k}_2$ are orthogonal. Moreover, \n",
    "  $\\left \\| \\mathbf{k}_1 \\right \\| =\\left \\| \\mathbf{k}_2 \\right \\| =\\sqrt{5}$, and so the vectors\n",
    "  \n",
    "  $\\mathbf{k}_1=\\left(\\begin{array}{r} \\frac{1}{\\sqrt{5}}\\\\ -\\frac{2}{\\sqrt{5}} \\end{array}\\right)$ and\n",
    "  $\\mathbf{k}_2=\\left(\\begin{array}{r} \\frac{2}{\\sqrt{5}}\\\\ \\frac{1}{\\sqrt{5}} \\end{array}\\right)$\n",
    "  \n",
    "  are orthogonal. Hence, the matrix\n",
    "  \n",
    "  $\\mathbf{P}=\n",
    "     \\left(\\begin{array}{rr} \\frac{1}{\\sqrt{5}} & \\frac{2}{\\sqrt{5}}\\\\ \n",
    "    -\\frac{2}{\\sqrt{5}} & \\frac{1}{\\sqrt{5}}\n",
    "    \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  is orthogonal. If we define the change of variables $\\mathbf{x}=\\mathbf{P}\\mathbf{\\hat{x}}$ \n",
    "  where $\\mathbf{\\hat{x}}=\\begin{pmatrix} \\hat{x} \\\\ \\hat{y} \\end{pmatrix}$, then the quadratic form can\n",
    "  be written\n",
    "  \n",
    "  $\\mathbf{x}^T\\mathbf{A}\\mathbf{x}=\n",
    "   \\mathbf{\\hat{x}}^T\\mathbf{P}^T\\mathbf{A}\\mathbf{P}\\mathbf{\\hat{x}}\n",
    "     =\\mathbf{\\hat{x}}^T\\mathbf{D}\\mathbf{\\hat{x}}\n",
    "     =\n",
    "   \\begin{pmatrix}\n",
    "     \\hat{x} & \\hat{y}\n",
    "   \\end{pmatrix}\n",
    "   \\left(\\begin{array}{rr}\n",
    "    -2 & 0\\\\ \n",
    "     0 & 3 \n",
    "   \\end{array}\\right)\n",
    "   \\begin{pmatrix}\n",
    "     \\hat{x} \\\\ \n",
    "     \\hat{y}\n",
    "   \\end{pmatrix}=1\n",
    "  $ or $-2\\hat{x}^2 +3\\hat{y}^2 =1$\n",
    "  \n",
    "  This last equation is recognized as the standard form of a hyperbola\n",
    "  \n",
    "  <img src=\"figures/ch08_figure05.png\" width=\"400\">\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.12\n",
    "\n",
    "* 7, 11, 13\n",
    "* 21, 23, 25\n",
    "* 31, 33, 37, 39\n",
    "* 41, 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.13 LU Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let $\\mathbf{A}$ be a square matrix. An *LU factorization* refers to the factorization of $\\mathbf{A}$ into \n",
    "  two factors – a lower triangular matrix $\\mathbf{L}$ and an upper triangular matrix $\\mathbf{U}$:\n",
    "\n",
    "  >$\\mathbf{A}=\\mathbf{L}\\mathbf{U}$\n",
    "  \n",
    "  Without a proper ordering or permutations in the matrix, the factorization may fail to materialize. \n",
    "  This is a procedural problem. It can be removed by simply reordering the rows of $\\mathbf{A}$.\n",
    "  It turns out that a proper permutation in rows (or columns) is sufficient for LU factorization. \n",
    "  LU factorization with partial pivoting (LUP) refers often to LU factorization with row permutations only\n",
    "  \n",
    "  >$\\mathbf{P}\\mathbf{A}=\\mathbf{L}\\mathbf{U}$\n",
    "  \n",
    "  where $\\mathbf{P}$ is a permutation matrix, which, when left-multiplied to $\\mathbf{A}$, reorders the rows of $\\mathbf{A}$. \n",
    "  It turns out that all square matrices can be factorized in this form.\n",
    "  If $\\mathbf{A}$ is invertible, then it admits an LU factorization if and only if all its leading principal minors are nonzero. \n",
    "  If $\\mathbf{A}$ is a singular matrix of rank $k$, then it admits an LU factorization if the first $k$ leading principal minors are nonzero\n",
    "\n",
    "* LU decomposition is basically a modified form of Gaussian elimination. We transform the matrix $\\mathbf{A}$ into \n",
    "  an upper triangular matrix $\\mathbf{U}$ by eliminating the entries below the main diagonal. \n",
    "  The **Doolittle algorithm** does the column-by-column elimination, starting from the left, by multiplying $\\mathbf{A}$ to \n",
    "  the left with atomic lower triangular matrices. It results in a *unit* lower triangular matrix and an upper triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doolittle Algorithm**\n",
    "\n",
    "* We define\n",
    "\n",
    "  $\\mathbf{A}^{(0)}=\\mathbf{A}$\n",
    "  \n",
    "* We eliminate the matrix elements below the main diagonal in the $k$-th column of $\\mathbf{A}^{(k -1)}$ \n",
    "  by adding to the $i$-th row of this matrix the $k$-th row multiplied by\n",
    "  \n",
    "  $\\displaystyle l_{i,k}=\\frac{a_{i,k}^{(k-1)}}{a_{k,k}^{(k-1)}}$ $\\text{ for } i=k+1, \\cdots, n$\n",
    "  \n",
    "  This can be done by multiplying $\\mathbf{A}^{(k -1)}$ to the left with the lower triangular matrix\n",
    "  \n",
    "  $\n",
    "  \\mathbf{L}_k=\n",
    "     \\begin{pmatrix}\n",
    "         1      & 0      &           & \\cdots &        & 0      \\\\ \n",
    "         0      & \\ddots & \\ddots    &        &        &        \\\\ \n",
    "                &        & 1         &        &        &        \\\\ \n",
    "        \\vdots  &        &-l_{k+1,k} &        &        & \\vdots \\\\ \n",
    "                &        & \\vdots    &        & \\ddots & 0      \\\\ \n",
    "         0      &        &-l_{n,k}   &        & 0      & 1\n",
    "     \\end{pmatrix}  \n",
    "  $\n",
    "  \n",
    "* We set\n",
    "  \n",
    "  $\\mathbf{A}^{(k)}=\\mathbf{L}_k\\mathbf{A}^{(k-1)}$, $k=1,\\cdots,n -1$\n",
    "  \n",
    "  After $n -1$ steps, we eliminated all the matrix elements below the main diagonal, \n",
    "  so we obtain an upper triangular matrix $\\mathbf{A}^{(n -1)}$. We find the decomposition\n",
    "  \n",
    "  $\n",
    "   \\mathbf{A}=\\mathbf{L}_1^{-1}\\mathbf{L}_1\\mathbf{A}^{(0)}=\\mathbf{L}_1^{-1}\\mathbf{A}^{(1)}\n",
    "     =\\mathbf{L}_1^{-1}\\mathbf{L}_2^{-1}\\mathbf{L}_2\\mathbf{A}^{(1)}=\\mathbf{L}_1^{-1}\\mathbf{L}_2^{-1}\\mathbf{A}^{(2)}\n",
    "     =\\cdots=\\mathbf{L}_1^{-1}\\cdots\\mathbf{L}_{n -1}^{-1}\\mathbf{A}^{(n -1)}\n",
    "  $\n",
    "  \n",
    "  Denote the upper triangular matrix $\\mathbf{A}^{(n -1)}$ by $\\mathbf{U}$, and $\\mathbf{L}=\\mathbf{L}_1^{-1}\\cdots\\mathbf{L}_{n -1}^{-1}$. \n",
    "  Because the inverse of a lower triangular matrix $\\mathbf{L}_k$ is again a lower triangular matrix, \n",
    "  and the multiplication of two lower triangular matrices is again a lower triangular matrix, \n",
    "  it follows that $\\mathbf{L}$ is a lower triangular matrix. Moreover, it can be seen that\n",
    "  \n",
    "  $\n",
    "  \\mathbf{L}=\n",
    "     \\begin{pmatrix}\n",
    "         1      & 0      &           & \\cdots &          & 0      \\\\ \n",
    "         l_{2,1}& \\ddots & \\ddots    &        &          &        \\\\ \n",
    "                &        & 1         &        &          &        \\\\ \n",
    "        \\vdots  &        & l_{k+1,k} &        &          & \\vdots \\\\ \n",
    "                &        & \\vdots    &        & 1        & 0      \\\\ \n",
    "         l_{n,1}& \\cdots & l_{n,k}   & \\cdots & l_{n,n-1}& 1\n",
    "     \\end{pmatrix}  \n",
    "  $\n",
    "  \n",
    "  We obtain $\\mathbf{A}=\\mathbf{L}\\mathbf{U}$\n",
    "  \n",
    "  **NOTE:** It is clear that in order for this algorithm to work, one needs to have $a_{k,k}^{(k-1)}$ at each step \n",
    "  (see the definition of $l_{i,k}$). If this assumption fails at some point, one needs to interchange $k$-th row \n",
    "  with another row below it before continuing. This is why an LU decomposition in general looks like \n",
    "  $\\mathbf{P}\\mathbf{A}=\\mathbf{L}\\mathbf{U}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "array([[ 7.,  3., -1.,  2.],\n",
      "       [ 3.,  8.,  1., -4.],\n",
      "       [-1.,  1.,  4., -1.],\n",
      "       [ 2., -4., -1.,  6.]])\n",
      "\n",
      "P =\n",
      "array([[1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.]])\n",
      "\n",
      "L =\n",
      "array([[ 1.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.42857143,  1.        ,  0.        ,  0.        ],\n",
      "       [-0.14285714,  0.21276596,  1.        ,  0.        ],\n",
      "       [ 0.28571429, -0.72340426,  0.08982036,  1.        ]])\n",
      "\n",
      "U =\n",
      "array([[ 7.        ,  3.        , -1.        ,  2.        ],\n",
      "       [ 0.        ,  6.71428571,  1.42857143, -4.85714286],\n",
      "       [ 0.        ,  0.        ,  3.55319149,  0.31914894],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.88622754]])\n"
     ]
    }
   ],
   "source": [
    "def lu_factor(A):\n",
    "    \"\"\"\n",
    "        LU factorization with partial pivoting\n",
    "    \n",
    "        PA = LU    \n",
    "        P(permutation), L(unit Lower triangular) and U(upper triangular) \n",
    "    \n",
    "        Return P, L, U\n",
    "    \"\"\"\n",
    "    n = A.shape[0]    \n",
    "    U = A.copy()\n",
    "    P = np.identity(n)\n",
    "    L = np.identity(n)\n",
    "\n",
    "    for k in range(n -1):\n",
    "\n",
    "        # Partial Pivoting\n",
    "        max_row_index = np.argmax(abs(U[k:n,k])) +k\n",
    "        P[[k, max_row_index]] = P[[max_row_index, k]]\n",
    "        U[[k, max_row_index]] = U[[max_row_index, k]]\n",
    "\n",
    "        # LU \n",
    "        for i in range(k +1, n):          \n",
    "            L[i,k] = U[i,k] /U[k,k]\n",
    "            U[i,k] = 0.0\n",
    "            for j in range(k +1, n):       \n",
    "                U[i,j] -= L[i,k] *U[k,j] \n",
    "\n",
    "    return P, L, U\n",
    "\n",
    "A = np.array([[7, 3, -1, 2], [3, 8, 1, -4], [-1, 1, 4, -1], [2, -4, -1, 6]], dtype='float64')\n",
    "P, L, U = lu_factor(A)\n",
    "\n",
    "print('A =')\n",
    "pprint.pprint(A)\n",
    "print('\\nP =')\n",
    "pprint.pprint(P)\n",
    "print('\\nL =')\n",
    "pprint.pprint(L)\n",
    "print('\\nU =')\n",
    "pprint.pprint(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P =\n",
      "array([[1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.]])\n",
      "\n",
      "L =\n",
      "array([[ 1.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.42857143,  1.        ,  0.        ,  0.        ],\n",
      "       [-0.14285714,  0.21276596,  1.        ,  0.        ],\n",
      "       [ 0.28571429, -0.72340426,  0.08982036,  1.        ]])\n",
      "\n",
      "U =\n",
      "array([[ 7.        ,  3.        , -1.        ,  2.        ],\n",
      "       [ 0.        ,  6.71428571,  1.42857143, -4.85714286],\n",
      "       [ 0.        ,  0.        ,  3.55319149,  0.31914894],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.88622754]])\n"
     ]
    }
   ],
   "source": [
    "import scipy.linalg\n",
    "\n",
    "P, L, U = scipy.linalg.lu(A)\n",
    "\n",
    "print('P =')\n",
    "pprint.pprint(P)\n",
    "print('\\nL =')\n",
    "pprint.pprint(L)\n",
    "print('\\nU =')\n",
    "pprint.pprint(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Solving Linear Equations**\n",
    "\n",
    "  Given a system of linear equations in matrix form\n",
    "  \n",
    "  $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$\n",
    "  \n",
    "  Suppose we have already obtained the LUP decomposition of $\\mathbf{A}$ such that $\\mathbf{P}\\mathbf{A}=\\mathbf{L}\\mathbf{U}$, \n",
    "  so $\\mathbf{L}\\mathbf{U}\\mathbf{x}=\\mathbf{P}\\mathbf{b}$\n",
    "  \n",
    "  In this case the solution is done in two logical steps:\n",
    "\n",
    "  * First, we solve the equation $\\mathbf{L}\\mathbf{y}=\\mathbf{P}\\mathbf{b}$ for $\\mathbf{y}$  \n",
    "  * Second, we solve the equation $\\mathbf{U}\\mathbf{x}=\\mathbf{y}$ for $\\mathbf{x}$\n",
    "  \n",
    "  <p>\n",
    "    \n",
    "  Note that in both cases we are dealing with triangular matrices ($\\mathbf{L}$ and $\\mathbf{U}$), \n",
    "  which can be solved directly by forward and backward substitution without using the Gaussian elimination process \n",
    "  (however we do need this process or equivalent to compute the LU decomposition itself). \n",
    "  The cost of solving a system of linear equations is approximately $\\frac{2}{3}n^{3}$ floating-point operations.\n",
    "    \n",
    "  The above procedure can be repeatedly applied to solve the equation multiple times for different $\\mathbf{b}$. \n",
    "  In this case it is faster (and more convenient) to do an LU decomposition of the matrix $\\mathbf{A}$ \n",
    "  once and then solve the triangular matrices for the different $\\mathbf{b}$, rather than using Gaussian elimination each time. \n",
    "  The matrices $\\mathbf{L}$ and $\\mathbf{U}$ could be thought to have *encoded* the Gaussian elimination process    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "b =\n",
      "array([1., 2., 3., 4.])\n",
      "\n",
      "x =\n",
      "array([-1.27619048,  1.87619048,  0.57142857,  2.43809524])\n"
     ]
    }
   ],
   "source": [
    "def ufsub(L, b):\n",
    "    \"\"\" Unit row oriented forward substitution \"\"\"\n",
    "    for i in range(L.shape[0]): \n",
    "        for j in range(i):\n",
    "            b[i] -= L[i,j] *b[j]\n",
    "    return b\n",
    "\n",
    "def bsub(U, y):\n",
    "    \"\"\" Row oriented backward substitution \"\"\"\n",
    "    for i in range(U.shape[0] -1, -1, -1): \n",
    "        for j in range(i +1, U.shape[1]):\n",
    "            y[i] -= U[i,j] *y[j]\n",
    "        y[i] = y[i] /U[i,i]\n",
    "    return y\n",
    "                    \n",
    "b = np.array([1, 2, 3, 4], dtype='float64')\n",
    "Pb = np.matmul(P, b)\n",
    "y = ufsub(L, Pb)\n",
    "x = bsub(U, y)\n",
    "\n",
    "print('\\nb =')\n",
    "pprint.pprint(b)\n",
    "print('\\nx =')\n",
    "pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Inverting a Matrix**\n",
    "\n",
    "  In matrix inversion, instead of vector $\\mathbf{b}$, we have matrix $\\mathbf{I}_n$ so that we are trying to find a matrix $\\mathbf{X}$\n",
    "  \n",
    "  $\\mathbf{L}\\mathbf{U}\\mathbf{X}=\\mathbf{I}_n$\n",
    "  \n",
    "  We can use the same algorithm presented earlier to solve for each column of matrix $\\mathbf{X}$\n",
    "  \n",
    "* **Computing the Determinant**\n",
    "\n",
    "  Given the LUP decomposition $\\mathbf{A}=\\mathbf{P}^{-1}\\mathbf{L}\\mathbf{U}$ of a square matrix $\\mathbf{A}$, \n",
    "  the determinant of $\\mathbf{A}$ can be computed straightforwardly as\n",
    "  \n",
    "  $\\displaystyle\\mathrm{det}(\\mathbf{A})=\\mathrm{det}(\\mathbf{P}^{-1})\\,\\mathrm{det}(\\mathbf{L})\\,\\mathrm{det}(\\mathbf{U})\n",
    "   =(-1)^s \\prod_{i=1}^n l_{ii}\\prod_{i=1}^n u_{ii}$\n",
    "   \n",
    "  where $s$ is the number of row exchanges in the permutation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 8.13\n",
    "\n",
    "* 1, 3, 5\n",
    "* 21, 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.14 Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Cryptography**\n",
    "\n",
    "  Cryptography is the study of making *secret writings* or *codes*. We will consider a system of encoding and decoding\n",
    "  messages that requires both the sender and the receiver to know:\n",
    "  \n",
    "  * a specified rule of correspondence between a set of symbols and a set of integers; and \n",
    "  * a specified *nonsingular* matrix $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **Example:** A correspondence between the first twenty-seven natural numbers and the letters of the alphabet and a blank space is given by\n",
    "  \n",
    "  > $\\scriptsize\n",
    "     \\begin{matrix}\n",
    "       0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 &10 &11 &12 &13 &14 &15 &16 &17 &18 &19 &20 &21 &22 &23 &24 &25 &26 \\\\ \n",
    "     \\text{space} & j & k & l & n & m & s & t & u & w & x & g & h & i & o & p & q & r & v & y & z & a & b & c & d & e & f \n",
    "    \\end{matrix}$\n",
    "  \n",
    "  The numerical equivalent of the message\n",
    "  \n",
    "  > **DR JOHN IS A DOUBLE SPY**\n",
    "  \n",
    "  is \n",
    "  \n",
    "  > $\\begin{matrix}\n",
    "        24 & 17 & 0 & 1 & 14 & 12 & 4 & 0 & 13 & 6 & 0 & 21 & 0 & 24 & 14 & 8 & 22 & 3 & 25 & 0 & 6 & 15 & 19\n",
    "      \\end{matrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =\n",
      "array([24, 17,  0,  1, 14, 12,  4,  0, 13,  6,  0, 21,  0, 24, 14,  8, 22,\n",
      "        3, 25,  0,  6, 15, 19])\n"
     ]
    }
   ],
   "source": [
    "cp = { 0:' ',  1:'j',  2:'k',  3:'l',  4:'n',  5:'m',  6:'s',  7:'t',    \n",
    "       8:'u',  9:'w', 10:'x', 11:'g', 12:'h', 13:'i', 14:'o', 15:'p',  \n",
    "      16:'q', 17:'r', 18:'v', 19:'y', 20:'z', 21:'a', 22:'b', 23:'c', \n",
    "      24:'d', 25:'e', 26:'f' }\n",
    "\n",
    "def convert_to_numeric(message):\n",
    "    \n",
    "    n = len(message)\n",
    "    numericalMessage = np.zeros(n, dtype = 'int32')\n",
    "    for i in range(n):\n",
    "        for code, letter in cp.items():\n",
    "            if message[i] == letter:\n",
    "                numericalMessage[i] = code\n",
    "                break\n",
    "    return numericalMessage\n",
    "\n",
    "ms = 'dr john is a double spy'\n",
    "\n",
    "M = convert_to_numeric(ms)\n",
    "\n",
    "print('M =')\n",
    "pprint.pprint(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  The sender will **encode** the message by means of the nonsingular matrix $\\mathbf{A}$ and the receiver will **decode**\n",
    "  the encoded message by means of the matrix $\\mathbf{A}^{-1}$. We choose to write the numerical message as the $3 \\times 8$ matrix\n",
    "  \n",
    "  >$\n",
    "  \\mathbf{M}=\n",
    "    \\left(\\begin{array}{rrrrrrrr}\n",
    "      24 & 17 & 0 & 1 & 14 & 12 & 4 & 0 \\\\ \n",
    "      13 & 6 & 0 & 21 & 0 & 24 & 14 & 8 \\\\ \n",
    "      22 & 3 & 25 & 0 & 6 & 15 & 19 & 0 \n",
    "    \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Note that the last entry $m_{38}$ has been simply padded with a space (the number $0$). A $3 \\times 8$ matrix allows us\n",
    "  to encode the message by means of a $3 \\times 3$ matrix. The encoding matrix $\\mathbf{A}$ is constructed, so that\n",
    "  \n",
    "  * $\\mathbf{A}$ is nonsingular\n",
    "  * $\\mathbf{A}$ has only integer entries, and\n",
    "  * $\\mathbf{A}^{-1}$ has only integer entries\n",
    " \n",
    "      \n",
    "  To accomplish the last criterion, we need only select the integer entries of $\\mathbf{A}$ in such a manner that \n",
    "  $\\mathrm{det} \\mathbf{A}=\\pm 1$. We choose\n",
    "      \n",
    "  >$\n",
    "  \\mathbf{A}=\n",
    "    \\left(\\begin{array}{rrr}\n",
    "        -1 & 0 &-1 \\\\\n",
    "        2 & 3 & 4 \\\\\n",
    "        2 & 4 & 5\n",
    "     \\end{array}\\right) \n",
    "  $\n",
    "  \n",
    "  and\n",
    "  \n",
    "  >$\n",
    "  \\mathbf{A}^{-1}=\n",
    "    \\left(\\begin{array}{rrr}\n",
    "        1 & 4 &-3 \\\\\n",
    "        2 & 3 &-2 \\\\\n",
    "       -2 &-4 & 3\n",
    "     \\end{array}\\right)  \n",
    "  $  \n",
    "      \n",
    "  You should verify that $\\mathrm{det} \\mathbf{A}=-1$. The original message is encoded as following:\n",
    "      \n",
    "  >$\\mathbf{B}=\\mathbf{A}\\mathbf{M}=\n",
    "    \\left(\\begin{array}{rrrrrrrr}\n",
    "     -46 & -20 & -25 & -1 & -20 & -27 & -23 & 0 \\\\ \n",
    "     175 &  64 & 100 & 65 & 52 & 156 & 126 & 24 \\\\ \n",
    "     210 &  73 & 125 & 86 & 58 & 195 & 159 & 32 \n",
    "    \\end{array}\\right)   \n",
    "  $\n",
    "  \n",
    "  It may be desirable to send the encoded message as letters of the alphabet rather than as numbers. \n",
    "  Thus we rewrite $\\mathbf{B}$ as $\\mathbf{B}'$ using integers modulo 27:\n",
    "  \n",
    "  >$\\mathbf{B'}=\n",
    "    \\left(\\begin{array}{rrrrrrrr}\n",
    "     8 & 7 & 2 & 26 & 7 & 0 & 4 & 0 \\\\ \n",
    "     13 &  10 & 19 & 11 & 25 & 21 & 18 & 24 \\\\ \n",
    "     21 &  19 & 17 & 5 & 4 & 6 & 24 & 5 \n",
    "    \\end{array}\\right)   \n",
    "  $ \n",
    "  \n",
    "  The encoded message to be sent in letters is\n",
    "  \n",
    "  > **UTKFT N IXYGEAVDAYRMNSDM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "array([[-1,  0, -1],\n",
      "       [ 2,  3,  4],\n",
      "       [ 2,  4,  5]])\n",
      "\n",
      "The inverse of A =\n",
      "array([[ 1,  4, -3],\n",
      "       [ 2,  3, -2],\n",
      "       [-2, -4,  3]])\n",
      "\n",
      "B =\n",
      "array([[-46, -20, -25,  -1, -20, -27, -23,   0],\n",
      "       [175,  64, 100,  65,  52, 156, 126,  24],\n",
      "       [210,  73, 125,  86,  58, 195, 159,  32]])\n",
      "\n",
      "B' =\n",
      "array([[ 8,  7,  2, 26,  7,  0,  4,  0],\n",
      "       [13, 10, 19, 11, 25, 21, 18, 24],\n",
      "       [21, 19, 17,  5,  4,  6, 24,  5]], dtype=int32)\n",
      "\n",
      "Encoded Text = UTKFT N IXYGEAVDAYRMNSDM \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_to_letter(M):\n",
    "    \n",
    "    M = M.flatten()\n",
    "    n = len(M)\n",
    "    message = \"\"\n",
    "    for i in range(n):\n",
    "        message += cp[M[i]]\n",
    "\n",
    "    return message\n",
    "\n",
    "n_app = (3 -len(M) % 3) % 3\n",
    "M = np.append(M, [0] *n_app).reshape((3, -1))\n",
    "\n",
    "A = np.array([[-1, 0, -1], [2, 3, 4], [2, 4, 5]])\n",
    "inv_A = np.rint(np.linalg.inv(A)).astype('int32')\n",
    "\n",
    "B = np.matmul(A, M)\n",
    "B_ = B % 27\n",
    "\n",
    "ms_encoded = convert_to_letter(B_)\n",
    "\n",
    "print('A =')\n",
    "pprint.pprint(A)\n",
    "print('\\nThe inverse of A =')\n",
    "pprint.pprint(inv_A)\n",
    "print('\\nB =')\n",
    "pprint.pprint(B)\n",
    "print('\\nB\\' =')\n",
    "pprint.pprint(B_)\n",
    "print('\\nEncoded Text =', ms_encoded.upper(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should try to imagine the difficulty of decoding the encoded message without prior knowledge. \n",
    "Using the original correspondence and $\\mathbf{A}$, the decoding is the straightforward computation\n",
    "\n",
    "> $\\mathbf{M}=\\mathbf{A}^{-1}\\mathbf{B}'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orginal Text = DR JOHN IS A DOUBLE SPY  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "B_ = convert_to_numeric(ms_encoded).reshape((3, -1))\n",
    "M_ = np.matmul(inv_A, B_) % 27\n",
    "\n",
    "ms_original = convert_to_letter(M_)\n",
    "\n",
    "print('\\nOrginal Text =', ms_original.upper(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **An Error-Correcting Code**\n",
    "\n",
    "  We are going to examine briefly the concept of digital communication, say, communication between \n",
    "  a satellite and a computer.\n",
    "  As a result, we will deal only with matrices whose entries are binary digits, namely $0$s and $1$s. \n",
    "  When addng and multipying such matrices,\n",
    "  we will use arithmetic modulo 2. This arithmetic is defined by the addition and multiplication tables\n",
    "\n",
    "| + | 0 | 1 |\n",
    "|---|---|---| \n",
    "| **0** | 0 | 1 |\n",
    "| **1** | 1 |<font color='red'> 0 </font>|\n",
    "\n",
    "| x | 0 | 1 |\n",
    "|---|---|---| \n",
    "| **0** | 0 | 0 |\n",
    "| **1** | 0 | 1 |\n",
    "\n",
    "  In digital communication the messages or words are binary $n$-tuples. An $n$-bit word is also said \n",
    "  to be a binary string of length $n$. By **encoding** a message, we mean a process whereby we transform\n",
    "  a word $\\mathbf{W}$ of length $n$ into another word $\\mathbf{C}$ of length $n +m$ by augmenting $\\mathbf{W}$\n",
    "  with $m$ additional bits, called **parity check bits**. An encoding/decoding scheme is called a **code**\n",
    "  \n",
    "  The **Hamming (7, 4) code** is an encoding/decoding scheme that can detect the presence of a single error\n",
    "  in a received message and can tell which bit must be corrected. In $(7, 4)$ code the encoding process\n",
    "  consists of transforming a 4-bit word \n",
    "  \n",
    "  >$\\mathbf{W}=\\begin{pmatrix} w_1 & w_2 & w_3 & w_4 \\end{pmatrix}$\n",
    "  \n",
    "  into a 7-bit code word\n",
    "  \n",
    "  >$\\mathbf{C}=\\begin{pmatrix} c_1 & c_2 & w_1 & c_3 & w_2 & w_3 & w_4 \\end{pmatrix}$\n",
    "  \n",
    "  where $c_1$, $c_2$, and $c_3$ denote the parity check bits and are defined in terms of the information\n",
    "  bits $w_1$, $w_2$, $w_3$, and $w_4$\n",
    "  \n",
    "  >$\n",
    "    \\begin{align*}\n",
    "        c_1 &= w_1 +w_2 +w_4\\\\ \n",
    "        c_2 &= w_1 +w_3 +w_4\\\\ \n",
    "        c_3 &= w_2 +w_3 +w_4\n",
    "    \\end{align*} \\;\\;\\text{(C1)} \n",
    "  $ \n",
    "  \n",
    "  We first observe that in modulo 2 arithmatic there are no negative numbers; the additive inverse\n",
    "  is $1$, not $-1$. With this in mind, we can write the system $\\text{(C1)}$ in the equivalent form\n",
    "  \n",
    "  >$\n",
    "    \\begin{align*}\n",
    "        c_3 &+ w_2 +w_3 +w_4 = 0\\\\\n",
    "        c_2 &+ w_1 +w_3 +w_4 = 0\\\\        \n",
    "        c_1 &+ w_1 +w_2 +w_4 = 0 \n",
    "    \\end{align*} \\;\\; \\text{(C2)}   \n",
    "  $ \n",
    "  \n",
    "  These are called **parity check equations**. As a matrix product, $\\text{(C2)}$ can be written\n",
    "  \n",
    "  >$\\mathbf{H}\\mathbf{C}^T=\\mathbf{0}$\n",
    "  \n",
    "  \n",
    "  where \n",
    "  \n",
    "  >$\\mathbf{H}=\n",
    "    \\begin{pmatrix}\n",
    "        0 & 0 & 0 & 1 & 1 & 1 & 1\\\\ \n",
    "        0 & 1 & 1 & 0 & 0 & 1 & 1\\\\\n",
    "        1 & 0 & 1 & 0 & 1 & 0 & 1\n",
    "    \\end{pmatrix}\n",
    "  $\n",
    "  \n",
    "  is called the **parity check matrix**. A closer inspection of $\\mathbf{H}$ shows \n",
    "  a surprising fact: The columns of $\\mathbf{H}$, left to right, are \n",
    "  the numbers $1$ through $7$ written in binary\n",
    "  \n",
    "  Let $\\mathbf{R}$ be a $1 \\times 7$ matrix representing the received message. The product\n",
    "  \n",
    "  >$\\mathbf{S}=\\mathbf{H}\\mathbf{R}^T$\n",
    "  \n",
    "  is called the **syndome** of $\\mathbf{R}$. If $\\mathbf{S}=\\mathbf{0}$, it is assumed that\n",
    "  the transmission is correct and that $\\mathbf{R}$ is the same as the original encoded \n",
    "  message $\\mathbf{C}$. The decoding of the message is accomplished by simply dropping the \n",
    "  three check bits in $\\mathbf{R}$\n",
    "  \n",
    "  Let \n",
    "  \n",
    "  >$\\mathbf{C}=\\begin{pmatrix} e_1 & e_2 & e_3 & e_4 & e_5 & e_6 & e_7 \\end{pmatrix}$\n",
    "  \n",
    "  be a *single-error noise* word added to $\\mathbf{C}$ during its transmission.\n",
    "  If noise changes the $i$-th bit, $e_i=1$. The received message is then \n",
    "  $\\mathbf{R}=\\mathbf{C}+\\mathbf{E}$. We see that\n",
    "  \n",
    "  >$\\begin{align*}\n",
    "      \\mathbf{S}&=\\mathbf{H}\\mathbf{R}^T\n",
    "            =\\mathbf{H}(\\mathbf{C}^T +\\mathbf{E}^T)=\\mathbf{H}\\mathbf{E}^T\\\\\n",
    "        &= e_1 \\begin{pmatrix} 0\\\\ 0\\\\ 1\\end{pmatrix}\n",
    "          +e_2 \\begin{pmatrix} 0\\\\ 1\\\\ 0\\end{pmatrix}\n",
    "          +e_3 \\begin{pmatrix} 0\\\\ 1\\\\ 1\\end{pmatrix}\n",
    "          +e_4 \\begin{pmatrix} 1\\\\ 0\\\\ 0\\end{pmatrix}\n",
    "          +e_5 \\begin{pmatrix} 1\\\\ 0\\\\ 1\\end{pmatrix} \n",
    "          +e_6 \\begin{pmatrix} 1\\\\ 1\\\\ 0\\end{pmatrix}\n",
    "          +e_7 \\begin{pmatrix} 1\\\\ 1\\\\ 1\\end{pmatrix}           \n",
    "    \\end{align*}    \n",
    "   $\n",
    "   \n",
    "   Hence, if $\\mathbf{S}\\neq\\mathbf{0}$, then $\\mathbf{S}$ must be one of \n",
    "   the columns of $\\mathbf{H}$. If $\\mathbf{R}$ contains a single error, we see that\n",
    "   the syndrome itself indicates which bit is in error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Method of Least Squares**\n",
    "\n",
    "  <img src=\"figures/ch08_figure06.png\" width=\"200\">\n",
    "\n",
    "  When performing experiments we often tabulate data in the form of ordered pairs $(x_1, y_1)$,\n",
    "  $(x_2, y_2)$, $\\cdots$, $(x_n, y_n)$, with each $x_i$ distinct. Given the data, it is then often\n",
    "  desirable to predict $y$ from $x$ by finding a mathematical model, that is, \n",
    "  a function $f(x)$ that approximates or fits the data\n",
    "  \n",
    "  We shall confine our attention to the problem of finding a linear polynomial\n",
    "  $f(x)=ax +b$ that best fits the data $(x_i, y_i)$, $i=1,\\cdots, n$. The procedure\n",
    "  for finding this linear function is known as **the method of least squares**\n",
    "  \n",
    "  One way to determine how well the linear function $f(x)=ax +b$ fits the data is to\n",
    "  measure the vertical distances between the data points $y_i$ and the graphs $f(x_i)$\n",
    "  \n",
    "  >$e_i=|y_i -f(x_i)|$, $\\;i=1,\\cdots, n$\n",
    "  \n",
    "  An actual approach is to find a linear function $f$ so that\n",
    "  the sum of the *squares* of all the $e_i$ values is a minimum\n",
    "  \n",
    "  >$\\displaystyle\\min_{a, b} E=\\min_{a, b} \\sum_{i=1}^n \\left[y_i -ax_i -b\\right]^2$\n",
    "  \n",
    "  Then to find the minimum value of $E$, we set the first partial derivatives with respect to\n",
    "  $a$ and $b$ to zero:\n",
    "  \n",
    "  >$\\displaystyle \\frac{\\partial E}{\\partial a}=0 \\;\\text{ and }\\; \\frac{\\partial E}{\\partial b}=0$\n",
    "  \n",
    "  The last two conditions yield, in turn,\n",
    "  \n",
    "  >$\n",
    "    \\begin{align*}\n",
    "        -2 \\sum_{i=1}^n x_i [y_i -a x_i -b] &= 0\\\\ \n",
    "        -2 \\sum_{i=1}^n [y_i -a x_i -b] &= 0\n",
    "    \\end{align*}  \n",
    "  $\n",
    "  \n",
    "  Expanding the sums and rearranging, we find the above system is the same as\n",
    "  \n",
    "  >$\n",
    "    \\begin{pmatrix}\n",
    "     \\displaystyle\\sum_{i=1}^n x_i^2 & \\displaystyle\\sum_{i=1}^n x_i\\\\ \n",
    "     \\displaystyle\\sum_{i=1}^n x_i   & n\n",
    "    \\end{pmatrix}\n",
    "    \\begin{pmatrix}\n",
    "      a \\\\ b\n",
    "    \\end{pmatrix}=\n",
    "    \\begin{pmatrix}\n",
    "     \\displaystyle \\sum_{i=1}^n x_i y_i\\\\ \\displaystyle \\sum_{i=1}^n y_i \\;\\;\\;\n",
    "    \\end{pmatrix}  \n",
    "  $\n",
    "  \n",
    "  and, in terms of matrices, is  equivalent to \n",
    "  \n",
    "  >$\\mathbf{A}^T\\mathbf{A}\\mathbf{x}=\\mathbf{A}^T\\mathbf{b}$\n",
    "  \n",
    "  where\n",
    "  \n",
    "  >$\n",
    "    \\mathbf{A}=\n",
    "    \\begin{pmatrix}\n",
    "     x_1 & 1\\\\ \n",
    "     x_2 & 1\\\\ \n",
    "     \\vdots & \\vdots\\\\ \n",
    "     x_n & 1 \n",
    "    \\end{pmatrix},\n",
    "    \\;\\mathbf{b}=\n",
    "    \\begin{pmatrix}\n",
    "     y_1\\\\\n",
    "     y_2\\\\ \n",
    "     \\vdots\\\\ \n",
    "     y_n\n",
    "    \\end{pmatrix},\n",
    "    \\;\\mathbf{x}=\n",
    "    \\begin{pmatrix}\n",
    "     a \\\\ b\n",
    "    \\end{pmatrix}\n",
    "    \\;\\;\\text{(LS)}\n",
    "  $ \n",
    "  \n",
    "  Unless the data points all lie on the same vertical line, the matrix $\\mathbf{A}^T\\mathbf{A}$\n",
    "  is nonsingular. Thus $\\text{(LS)}$ has the unique solution\n",
    "  \n",
    "  >$\n",
    "    \\mathbf{x} =\\left(\\mathbf{A}^T \\mathbf{A} \\right)^T \\mathbf{A}^T \\mathbf{b}\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Discrete Compartmental Models**\n",
    "\n",
    "  Strontium 90 is deposited into pastureland by rainfall. To study how this material is \n",
    "  cycled through the ecosystem, we divide the system into the compartments shown in the following\n",
    "\n",
    "  <img src=\"figures/ch08_figure07.png\" width=\"300\">\n",
    "  \n",
    "  Suppose that $\\Delta t=1$ month and the transfer coefficients (which have been estimated\n",
    "  experimentally) shown in the figure are measured in fraction/month. Suppose that rainfall has\n",
    "  deposited the strotium 90 into the compartments so that\n",
    "  \n",
    "  >$\\mathbf{x}_0=\n",
    "   \\begin{pmatrix}\n",
    "    20\\\\ \n",
    "    60\\\\ \n",
    "    15\\\\ \n",
    "    20\n",
    "   \\end{pmatrix}$\n",
    "   \n",
    "  Units might be grams per hectare. Compute the states of the ecosystem over the next 12 months\n",
    "  \n",
    "  *Solution* From the data in figure, we see that transfer matrix $\\mathbf{T}$ is\n",
    "  \n",
    "  >$\n",
    "    \\mathbf{T}=\n",
    "    \\begin{pmatrix}\n",
    "     0.85 & 0.01 & 0   & 0 \\\\ \n",
    "     0.05 & 0.98 & 0.2 & 0 \\\\ \n",
    "     0.1  & 0    & 0.8 & 0 \\\\ \n",
    "     0    & 0.01 & 0   & 1\n",
    "    \\end{pmatrix}  \n",
    "  $\n",
    "  \n",
    "  We must compute $\\mathbf{x}_1$, $\\mathbf{x}_2$, $\\cdots$, $\\mathbf{x}_{12}$ by using\n",
    "  the recursion formula $\\mathbf{x}_{n+1}=\\mathbf{T}\\mathbf{x}_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month   Grasses      Soil   Dead_OM   Streams\n",
      "    0     20.00     60.00     15.00     20.00\n",
      "    1     17.60     62.80     14.00     20.60\n",
      "    2     15.59     65.22     12.96     21.23\n",
      "    3     13.90     67.29     11.93     21.88\n",
      "    4     12.49     69.03     10.93     22.55\n",
      "    5     11.31     70.46      9.99     23.24\n",
      "    6     10.32     71.61      9.13     23.95\n",
      "    7      9.48     72.52      8.33     24.66\n",
      "    8      8.79     73.21      7.61     25.39\n",
      "    9      8.20     73.71      6.97     26.12\n",
      "   10      7.71     74.04      6.40     26.86\n",
      "   11      7.29     74.22      5.89     27.60\n",
      "   12      6.94     74.28      5.44     28.34\n"
     ]
    }
   ],
   "source": [
    "T = np.array([[0.85, 0.01, 0, 0], [0.05, 0.98, 0.2, 0],\n",
    "             [0.10, 0, 0.80, 0], [0, 0.01, 0, 1]])\n",
    "x = np.array([20, 60, 15, 20]).T\n",
    "\n",
    "print('Month   Grasses      Soil   Dead_OM   Streams')\n",
    "for month in range(13):   \n",
    "    print('%5d %9.2f %9.2f %9.2f %9.2f' %(month, x[0], x[1], x[2], x[3]))  \n",
    "    x = np.matmul(T, x)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
